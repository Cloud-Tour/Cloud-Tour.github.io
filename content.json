{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://Cloud-Tour.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-10-14T13:41:36.430Z","updated":"2022-10-06T02:48:58.718Z","comments":false,"path":"/404.html","permalink":"http://cloud-tour.github.io/404.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-10-06T02:48:58.721Z","updated":"2022-10-06T02:48:58.721Z","comments":true,"path":"links/index.html","permalink":"http://cloud-tour.github.io/links/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-10-06T02:48:58.720Z","updated":"2022-10-06T02:48:58.720Z","comments":false,"path":"books/index.html","permalink":"http://cloud-tour.github.io/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-10-06T02:48:58.720Z","updated":"2022-10-06T02:48:58.720Z","comments":false,"path":"about/index.html","permalink":"http://cloud-tour.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2022-10-06T02:48:58.721Z","updated":"2022-10-06T02:48:58.721Z","comments":false,"path":"categories/index.html","permalink":"http://cloud-tour.github.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-10-06T04:17:29.443Z","updated":"2022-10-06T02:48:58.722Z","comments":false,"path":"repository/index.html","permalink":"http://cloud-tour.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-10-06T02:48:58.722Z","updated":"2022-10-06T02:48:58.722Z","comments":false,"path":"tags/index.html","permalink":"http://cloud-tour.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"juc","slug":"juc","date":"2023-02-17T13:02:02.380Z","updated":"2023-02-17T13:03:59.388Z","comments":true,"path":"2023/02/17/juc/","link":"","permalink":"http://cloud-tour.github.io/2023/02/17/juc/","excerpt":"","text":"1.进程和线程 进程 进程就是用来加载指令、管理内存、管理 IO 的 当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。 线程 一个进程之内可以分为一到多个线程。 一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给 CPU 执行 Java 中，线程作为最小调度单位，进程作为资源分配的最小单位。 在 windows 中进程是不活动的，只是作为线程的容器 区别 进程基本上相互独立的，而线程存在于进程内，是进程的一个子集 进程拥有共享的资源，如内存空间等，供其内部的线程共享 进程间通信较为复杂 同一台计算机的进程通信称为 IPC（Inter-process communication） 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP 线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低 其他区别 1、因为进程拥有独立的堆栈空间和数据段，所以每当启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这对于多进程来说十分“奢侈”，系统开销比较大，而线程不一样，线程拥有独立的堆栈空间，但是共享数据段，它们彼此之间使用相同的地址空间，共享大部分数据，比进程更节俭，开销比较小，切换速度也比进程快，效率高，但是正由于进程之间独立的特点，使得进程安全性比较高，也因为进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。一个线程死掉就等于整个进程死掉。 2、体现在通信机制上面，正因为进程之间互不干扰，相互独立，进程的通信机制相对很复杂，譬如管道，信号，消息队列，共享内存，套接字等通信机制，而线程由于共享数据段所以通信机制很方便。。 3、体现在CPU系统上面，线程使得CPU系统更加有效，因为操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。 4、体现在程序结构上，举一个简明易懂的列子：当我们使用进程的时候，我们不自主的使用if else嵌套来判断pid，使得程序结构繁琐，但是当我们使用线程的时候，基本上可以甩掉它，当然程序内部执行功能单元需要使用的时候还是要使用，所以线程对程序结构的改善有很大帮助。 2.synchronized原理 java对象头 普通对象 数组对象 64 位虚拟机 Mark Word Monitor Monitor 被翻译为监视器或管程 每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针 Monitor 结构如下 刚开始 Monitor 中 Owner 为 null 当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor中只能有一 个 Owner 在 Thread-2 上锁的过程中，如果 Thread-3，Thread-4，Thread-5 也来执行 synchronized(obj)，就会进入 EntryList BLOCKED Thread-2 执行完同步代码块的内容，然后唤醒 EntryList 中等待的线程来竞争锁，竞争的时是非公平的 图中 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但条件不满足进入 WAITING 状态的线程，后面讲 wait-notify 时会分析 注意： synchronized 必须是进入同一个对象的 monitor 才有上述的效果 不加 synchronized 的对象不会关联监视器，不遵从以上规则 轻量级锁 轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以 使用轻量级锁来优化。 轻量级锁对使用者是透明的，即语法仍然是 synchronized 假设有两个方法同步块，利用同一个对象加锁 123456789101112static final Object obj = new Object();public static void method1() &#123; synchronized( obj ) &#123; // 同步块 A method2(); &#125;&#125;public static void method2() &#123; synchronized( obj ) &#123; // 同步块 B &#125;&#125; 创建锁记录（Lock Record）对象，每个线程都的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word 让锁记录中 Object reference 指向锁对象，并尝试用 cas 替换 Object 的 Mark Word，将 Mark Word 的值存 入锁记录 如果 cas 替换成功，对象头中存储了 锁记录地址和状态 00 ，表示由该线程给对象加锁，这时图示如下 如果 cas 失败，有两种情况 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数 当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重 入计数减一 当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程 锁膨胀 如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有 竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁 这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 即为 Object 对象申请 Monitor 锁，让 Object 指向重量级锁地址 然后自己进入 Monitor 的 EntryList BLOCKED 当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁 流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程 自旋优化 重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步 块，释放了锁），这时当前线程就可以避免阻塞。 自旋重试成功的情况 自旋重试失败的情况 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会 高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 Java 7 之后不能控制是否开启自旋功能 偏向锁 轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作。 Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现 这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有 偏向状态 对象头格式 一个对象创建时： 如果开启了偏向锁（默认开启），那么对象创建后，markword 值为 0x05 即最后 3 位为 101，这时它的 thread、epoch、age 都为 0 偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加 VM 参数 - XX:BiasedLockingStartupDelay=0 来禁用延迟 如果没有开启偏向锁，那么对象创建后，markword 值为 0x01 即最后 3 位为 001，这时它的 hashcode、 age 都为 0，第一次用到 hashcode 时才会赋值 3.wait、notify原理 Owner 线程发现条件不满足，调用 wait 方法，即可进入 WaitSet 变为 WAITING 状态 BLOCKED 和 WAITING 的线程都处于阻塞状态，不占用 CPU 时间片 BLOCKED 线程会在 Owner 线程释放锁时唤醒 WAITING 线程会在 Owner 线程调用 notify 或 notifyAll 时唤醒，但唤醒后并不意味者立刻获得锁，仍需进入 EntryList 重新竞争 4.park unpark 原理 每个线程都有自己的一个 Parker 对象，由三部分组成 _counter ， _cond 和 _mutex 打个比喻 _ 线程就像一个旅人，Parker 就像他随身携带的背包，条件变量就好比背包中的帐篷。_counter 就好比背包中 的备用干粮（0 为耗尽，1 为充足） 调用 park 就是要看需不需要停下来歇息 如果备用干粮耗尽，那么钻进帐篷歇息 如果备用干粮充足，那么不需停留，继续前进 调用 unpark，就好比令干粮充足 如果这时线程还在帐篷，就唤醒让他继续前进 如果这时线程还在运行，那么下次他调用 park 时，仅是消耗掉备用干粮，不需停留继续前进 因为背包空间有限，多次调用 unpark 仅会补充一份备用干粮 5.ReentrantLock 相对于 synchronized 它具备如下特点 可中断 可以设置超时时间 可以设置为公平锁 支持多个条件变量 与 synchronized 一样，都支持可重入 基本用法： 12345678// 获取锁reentrantLock.lock();try &#123; // 临界区&#125; finally &#123; // 释放锁 reentrantLock.unlock();&#125; 条件变量 synchronized 中也有条件变量，就是我们讲原理时那个 waitSet 休息室，当条件不满足时进入 waitSet 等待 ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比 synchronized 是那些不满足条件的线程都在一间休息室等消息 而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒 使用要点： await 前需要获得锁 await 执行后，会释放锁，进入 conditionObject 等待 await 的线程被唤醒（或打断、或超时）取重新竞争 lock 锁 竞争 lock 锁成功后，从 await 后继续执行 非公平锁实现原理 先从构造器开始看，默认为非公平锁实现 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; NonfairSync 继承自 AQS 没有竞争时 第一个竞争出现时 Thread-1 执行了 CAS 尝试将 state 由 0 改为 1，结果失败 进入 tryAcquire 逻辑，这时 state 已经是1，结果仍然失败 接下来进入 addWaiter 逻辑，构造 Node 队列 图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态 Node 的创建是懒惰的 其中第一个 Node 称为 Dummy（哑元）或哨兵，用来占位，并不关联线程 当前线程进入 acquireQueued 逻辑 acquireQueued 会在一个死循环中不断尝试获得锁，失败后进入 park 阻塞 如果自己是紧邻着 head（排第二位），那么再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的 waitStatus 改为 -1，这次返回 false shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回 true 进入 parkAndCheckInterrupt， Thread-1 park（灰色表示） 再次有多个线程经历上述过程竞争失败，变成这个样子 Thread-0 释放锁，进入 tryRelease 流程，如果成功 设置 exclusiveOwnerThread 为 null state = 0 当前队列不为 null，并且 head 的 waitStatus = -1，进入 unparkSuccessor 流程 找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1 回到 Thread-1 的 acquireQueued 流程 如果加锁成功（没有竞争），会设置 exclusiveOwnerThread 为 Thread-1，state = 1 head 指向刚刚 Thread-1 所在的 Node，该 Node 清空 Thread 原本的 head 因为从链表断开，而可被垃圾回收 如果这时候有其它线程来竞争（非公平的体现），例如这时有 Thread-4 来了 如果不巧又被 Thread-4 占了先 Thread-4 被设置为 exclusiveOwnerThread，state = 1 Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞 可重入原理 条件变量实现原理 每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject await 流程 开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程 创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部 接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁 unpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功 park 阻塞 Thread-0 signal 流程 假设 Thread-1 要来唤醒 Thread-0 进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在 Node 执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的 waitStatus 改为 -1 Thread-1 释放锁，进入 unlock 流程，略 6.volatile原理 volatile 的底层实现原理是内存屏障，Memory Barrier（Memory Fence） 对 volatile 变量的写指令后会加入写屏障 对 volatile 变量的读指令前会加入读屏障 保证可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 public void actor2(I_Result r) &#123; num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 &#125; &lt;!--code￼3--&gt; 保证有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 public void actor2(I_Result r) &#123; num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 &#125; &lt;!--code￼4--&gt; 还是那句话，不能解决指令交错(字节码层面)： 写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证读跑到它前面去 而有序性的保证也只是保证了本线程内相关代码不被重排序 7.线程池 线程池（thread pool）：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，对线程统一管理。 线程池就是存放线程的池子，池子里存放了很多可以复用的线程。 创建线程和销毁线程的花销是比较大的（手动new Thread 类），创建和消耗线程的时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程是比较消耗资源的。（我们可以把创建和销毁的线程的过程去掉）。 线程池状态 ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量 从数字上比较，TERMINATED &gt; TIDYING &gt; STOP &gt; SHUTDOWN &gt; RUNNING 这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作 进行赋值 running：初始化后的状态，表示线程池可以处理任务。 shutdown：调用线程池的shutdown方法会使线程进入shutdown状态，从而调用execute的时候会抛出异常。但如果阻塞队列中还有任务，则会先将阻塞队列中的认为执行完，才会后收所有线程。 stop：调用线程池的shutdownnow方法会使线程进入stop状态，既不能接受新的任务，也不能把阻塞队列中的任务执行完。 tidying：在执行玩shutdownnow方法的时候，关闭完所有线程的时候，就会调用tryTerminate（）方法 terminated：线程池处于TIDYING状态后，会执行terminated（）方法，执行完后就i进入terminated状态，在ThreadPoolExecutor中的terminated（）是一个空方法，可以自定义线程池重写这个方法，实现自定义的业务逻辑。 工作流程 提交任务 当工作线程数小于核心线程数时，直接创建新的核心工作线程 当工作线程数不小于核心线程数时，就需要尝试将任务添加到阻塞队列中去 如果能够加入成功，说明队列还没有满，那么需要做以下的二次验证来保证添加进去的任务能够成功被执行 验证当前线程池的运行状态，如果是非RUNNING状态，则需要将任务从阻塞队列中移除，然后拒绝该任务 验证当前线程池中的工作线程的个数，如果为0，则需要主动添加一个空工作线程来执行刚刚添加到阻塞队列中的任务 如果加入失败，则说明队列已经满了，那么这时就需要创建新的“临时”工作线程来执行任务 如果创建成功，则直接执行该任务 如果创建失败，则说明工作线程数已经等于最大线程数了，则只能拒绝该任务了 构造方法 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize 核心线程数目 (最多保留的线程数) CPU密集型：corePoolSize = CPU核数 + 1 IO密集型：corePoolSize = CPU核数 * 2 maximumPoolSize 最大线程数目 keepAliveTime 生存时间 - 针对救急线程 unit 时间单位 - 针对救急线程 workQueue 阻塞队列 threadFactory 线程工厂 - 可以为线程创建时起个好名字 handler 拒绝策略（可通过实现RejectedExecutionHandler 接口自定义拒绝策略） 工作队列 1、无界队列 队列大小无限制，常用的为无界的LinkedBlockingQueue，使用该队列作为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM。阅读代码发现，Executors.newFixedThreadPool 采用就是 LinkedBlockingQueue，而博主踩到的就是这个坑，当QPS很高，发送数据很大，大量的任务被添加到这个无界LinkedBlockingQueue 中，导致cpu和内存飙升服务器挂掉。 当然这种队列，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 2、有界队列 当使用有限的 maximumPoolSizes 时，有界队列有助于防止资源耗尽，但是可能较难调整和控制。常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。 使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。 3、同步移交队列 如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列。 newFixedThreadPool 123456public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 特点 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间 阻塞队列是无界的，可以放任意数量的任务 评价 适用于任务量已知，相对耗时的任务 newCachedThreadPool 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 特点 核心线程数是 0， 最大线程数是 Integer.MAX_VALUE，救急线程的空闲生存时间是 60s，意味着 全部都是救急线程（60s 后可以回收） 救急线程可以无限创建 队列采用了 SynchronousQueue 实现特点是，它没有容量，没有线程来取是放不进去的（一手交钱、一手交 货） 评价 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1分钟后释放线 程。 适合任务数比较密集，但每个任务执行时间较短的情况 newSingleThreadExecutor 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 使用场景： 希望多个任务排队执行。线程数固定为 1，任务数多于 1 时，会放入无界队列排队。任务执行完毕，这唯一的线程 也不会被释放。 区别： 自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一 个线程，保证池的正常工作 Executors.newSingleThreadExecutor() 线程个数始终为1，不能修改 FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因 此不能调用 ThreadPoolExecutor 中特有的方法 Executors.newFixedThreadPool(1) 初始时为1，以后还可以修改 对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改 任务提交 123456789101112131415161718192021222324// 执行任务void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 关闭线程池 123456789101112131415161718192021222324/*线程池状态变为 SHUTDOWN - 不会接收新任务 - 但已提交任务会执行完 - 此方法不会阻塞调用线程的执行*/void shutdown();/*线程池状态变为 STOP - 不会接收新任务 - 会将队列中的任务返回 - 并用 interrupt 的方式中断正在执行的任务*/List&lt;Runnable&gt; shutdownNow();// 不在 RUNNING 状态的线程池，此方法就返回 trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，可以利用此方法等待 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 任务调度线程池 使用 ScheduledExecutorService 123456789ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);// 添加两个任务，希望它们都在 1s 后执行executor.schedule(() -&gt; &#123; System.out.println(&quot;任务1，执行时间：&quot; + new Date()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125;&#125;, 1000, TimeUnit.MILLISECONDS);executor.schedule(() -&gt; &#123; System.out.println(&quot;任务2，执行时间：&quot; + new Date());&#125;, 1000, TimeUnit.MILLISECONDS); scheduleAtFixedRate 循环执行例子 12345ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; &#123; log.debug(&quot;running...&quot;);&#125;, 1, 1, TimeUnit.SECONDS); 输出： scheduleAtFixedRate 例子（任务执行时间超过了间隔时间）： 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; &#123; log.debug(&quot;running...&quot;); sleep(2);&#125;, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，接下来，由于任务执行时间 &gt; 间隔时间，间隔被『撑』到了 2s scheduleWithFixedDelay 例子： 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleWithFixedDelay(()-&gt; &#123; log.debug(&quot;running...&quot;); sleep(2);&#125;, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，scheduleWithFixedDelay 的间隔是 上一个任务结束 &lt;-&gt; 延时 &lt;-&gt; 下一个任务开始 所 以间隔都是 3s 评价 整个线程池表现为：线程数固定，任务数多于线程数时，会放入无界队列排队。任务执行完毕，这些线 程也不会被释放。用来执行延迟或反复执行的任务 Fork/Join Fork/Join 是 JDK 1.7 加入的新的线程池实现，它体现的是一种分治思想，适用于能够进行任务拆分的 cpu 密集型 运算 所谓的任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列、都可以用分治思想进行求解 Fork/Join 在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升了运算效率 Fork/Join 默认会创建与 cpu 核心数大小相同的线程池 使用： 提交给 Fork/Join 线程池的任务需要继承 RecursiveTask（有返回值）或 RecursiveAction（没有返回值），例如下 面定义了一个对 1~n 之间的整数求和的任务 123456789101112131415161718192021222324252627282930@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask1 extends RecursiveTask&lt;Integer&gt; &#123; int n; public AddTask1(int n) &#123; this.n = n; &#125; @Override public String toString() &#123; return &quot;&#123;&quot; + n + &#x27;&#125;&#x27;; &#125; @Override protected Integer compute() &#123; // 如果 n 已经为 1，可以求得结果了 if (n == 1) &#123; log.debug(&quot;join() &#123;&#125;&quot;, n); return n; &#125; // 将任务进行拆分(fork) AddTask1 t1 = new AddTask1(n - 1); t1.fork(); log.debug(&quot;fork() &#123;&#125; + &#123;&#125;&quot;, n, t1); // 合并(join)结果 int result = n + t1.join(); log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, n, t1, result); return result; &#125;&#125; 然后提交给 ForkJoinPool 来执行 12345public static void main(String[] args) &#123; ForkJoinPool pool = new ForkJoinPool(4); System.out.println(pool.invoke(new AddTask1(5)));&#125; 结果： 8.AQS 概述 全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架 AQS定义了一套多线程访问共享资源的同步模板，解决了实现同步器时涉及的大量细节问题，能够极大地减少实现工作 AQS的组成结构 三部分组成：volatile int state同步状态、Node组成的CLH队列、ConditionObject条件变量（包含Node组成的条件单向队列）。 特点： 用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁 getState - 获取 state 状态 setState - 设置 state 状态 compareAndSetState - cas 机制设置 state 状态 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源 ReentrantLock的state用来表示是否有锁资源 ReentrantReadWriteLock的state高16位代表读锁状态，低16位代表写锁状态 Semaphore的state用来表示可用信号的个数 CountDownLatch的state用来表示计数器的值 提供了基于 FIFO （先进先出）的等待队列，类似于 Monitor 的 EntryList 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet 子类主要实现这样一些方法（默认抛出 UnsupportedOperationException） tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively 获取锁的姿势： 1234// 如果获取锁失败if (!tryAcquire(arg)) &#123; // 入队, 可以选择阻塞当前线程 park unpark&#125; 释放锁的姿势 1234// 如果释放锁成功if (tryRelease(arg)) &#123; // 让阻塞线程恢复运行&#125; 例子 实现不可重入锁 自定义同步器 1234567891011121314151617181920212223242526272829303132333435final class MySync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int acquires) &#123; if (acquires == 1)&#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; &#125; return false; &#125; @Override protected boolean tryRelease(int acquires) &#123; if(acquires == 1) &#123; if(getState() == 0) &#123; throw new IllegalMonitorStateException(); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; return false; &#125; protected Condition newCondition() &#123; return new ConditionObject(); &#125; @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125;&#125; 自定义锁 有了自定义同步器，很容易复用 AQS ，实现一个功能完备的自定义锁 12345678910111213141516171819202122232425262728293031323334353637383940class MyLock implements Lock &#123; static MySync sync = new MySync(); @Override // 尝试，不成功，进入等待队列 public void lock() &#123; sync.acquire(1); &#125; @Override // 尝试，不成功，进入等待队列，可打断 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override // 尝试一次，不成功返回，不进入队列 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override // 尝试，不成功，进入等待队列，有时限 public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override // 释放锁 public void unlock() &#123; sync.release(1); &#125; @Override // 生成条件变量 public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; CLH队列 CLH是AQS内部维护的FIFO（先进先出）双端双向队列（方便尾部节点插入），基于链表数据结构，当一个线程竞争资源失败，就会将等待资源的线程封装成一个Node节点，通过CAS原子操作插入队列尾部，最终不同的Node节点连接组成了一个CLH队列，所以说AQS通过CLH队列管理竞争资源的线程，个人总结CLH队列具有如下几个优点： 先进先出保证了公平性 非阻塞的队列，通过自旋锁和CAS保证节点插入和移除的原子性，实现无锁快速插入 采用了自旋锁思想，所以CLH也是一种基于链表的可扩展、高性能、公平的自旋锁 流程 线程获取资源失败，封装成Node节点从CLH队列尾部入队并阻塞线程，某线程释放资源时会把CLH队列首部Node节点关联的线程唤醒（此处的首部是指第二个节点，后面会细说），再次获取资源。， 入队 获取资源失败的线程需要封装成Node节点，接着尾部入队，在AQS中提供addWaiter函数完成Node节点的创建与入队。 添加节点的时候，如果从CLH队列已经存在，通过CAS快速将当前节点添加到队列尾部，如果添加失败或队列不存在，则指向enq函数自旋入队。 通过自旋CAS尝试往队列尾部插入节点，直到成功，自旋过程如果发现CLH队列不存在时会初始化CLH队列，入队过程流程如下图： 第一次循环 刚开始C L H队列不存在，head与tail都指向null 要初始化C L H队列，会创建一个哨兵节点，head与tail都指向哨兵节点 第二次循环 当前线程节点的前驱节点指向尾部节点（哨兵节点） 设置当前线程节点为尾部，tail指向当前线程节点 前尾部节点的后驱节点指向当前线程节点（当前尾部节点） 最后结合addWaiter与enq函数的入队流程图如下 出队 CLH队列中的节点都是获取资源失败的线程节点，当持有资源的线程释放资源时，会将head.next指向的线程节点唤醒（CLH队列的第二个节点），如果唤醒的线程节点获取资源成功，线程节点清空信息设置为头部节点（新哨兵节点），原头部节点出队（原哨兵节点）acquireQueued函数中的部分代码 假设获取资源成功，更换头部节点，并把头部节点的信息清除变成哨兵节点，注意这个过程是不需要使用CAS来保证，因为只有一个线程能够成功获取到资源。 条件变量 Object的wait、notify函数是配合Synchronized锁实现线程间同步协作的功能，A Q S的ConditionObject条件变量也提供这样的功能，通过ConditionObject的await和signal两类函数完成。不同于Synchronized锁，一个A Q S可以对应多个条件变量，而Synchronized只有一个 如上图所示，ConditionObject内部维护着一个单向条件队列，不同于C H L队列，条件队列只入队执行await的线程节点，并且加入条件队列的节点，不能在C H L队列， 条件队列出队的节点，会入队到C H L队列。 当某个线程执行了ConditionObject的await函数，阻塞当前线程，线程会被封装成Node节点添加到条件队列的末端，其他线程执行ConditionObject的signal函数，会将条件队列头部线程节点转移到C H L队列参与竞争资源，具体流程如下图 共享方式 AQS定义两种资源共享方式。无论是独占锁还是共享锁，本质上都是对AQS内部的一个变量state的获取。state是一个原子的int变量，用来表示锁状态、资源数等。 ① 独占锁(Exclusive)模式：只能被一个线程获取到(Reentrantlock)。 ② 共享锁(Share)模式：可以被多个线程同时获取(Semaphore/CountDownLatch/ReadWriteLock)。 state机制 提供volatile变量state，用于同步线程之间的共享状态。通过 CAS 和 volatile 保证其原子性和可见性。核心要点： state 用 volatile 修饰，保证多线程中的可见性 getState() 和 setState() 方法采用final修饰，限制AQS的子类重写它们两 compareAndSetState() 方法采用乐观锁思想的CAS算法，也是采用final修饰的，不允许子类重写 state应用案例： 案例 描述 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease） ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理 9.Semaphore 用来限制能同时访问共享资源的线程上限。 Semaphore是一个计数信号量，它的本质是一个&quot;共享锁&quot;。信号量维护了一个信号量许可集。线程可以通过调用acquire()来获取信号量的许可；当信号量中有可用的许可时，线程能获取该许可；否则线程必须等待，直到有可用的许可为止。 线程可以通过release()来释放它所持有的信号量许可。 流程 Semaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后 停车场显示空余车位减一 刚开始，permits（state）为 3，这时 5 个线程来获取资源 假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列 park 阻塞 这时 Thread-4 释放了 permits，状态如下 接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接 下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态 10. CountDownLatch 用来进行线程同步协作，等待所有线程完成倒计时。 其中构造参数用来初始化等待计数值，await() 用来等待计数归零，countDown() 用来让计数减一 CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 CountDownLatch和CyclicBarrier的区别 CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier 11.CyclicBarrier 循环栅栏，用来进行线程协作，等待线程满足某个计数。构造时设置『计数个数』，每个线程执 行到某个需要“同步”的时刻调用 await() 方法进行等待，当等待的线程数满足『计数个数』时，继续执行 CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 12.多线程通信 通信 多线程通讯的方式主要包括以下几种： 使用volatile关键词：基于共享内存的思想 使用Synchronized+Object类的wait()/notify()/notifyAll()方法 使用JUC工具类CountDownLatch：基于共享变量state实现 使用Lock（ReentrantLock）结合Condition 基于LockSupport实现线程间的阻塞和唤醒 线程协作 sleep/yield/join sleep() 让当前线程暂停指定的时间（毫秒） wait方法依赖于同步，而sleep方法可以直接调用 sleep方法只是暂时让出CPU的执行权，并不释放锁，而wait方法则需要释放锁 yield() 暂停当前线程，让出当前CPU的使用权，以便其它线程有机会执行 不能指定暂停的时间，并且也不能保证当前线程马上停止 会让当前线程从运行状态转变为就绪状态 yield只能使同优先级或更高优先级的线程有执行的机会 join() 等待调用 join 方法的线程执行结束，才执行后面的代码 其调用一定要在 start 方法之后（看源码可知） 作用是父线程等待子线程执行完成后再执行（即将异步执行的线程合并为同步的线程） wait/notify/notifyAll 一般需要配合synchronized一起使用。Object的主要方法如下： wait()：阻塞当前线程，直到 notify 或者 notifyAll 来唤醒 notify()：只能唤醒一个处于 wait 的线程 notifyAll()：唤醒全部处于 wait 的线程 await/signal/signalAll 使用显式的 Lock 和 Condition 对象： await()：当前线程进入等待状态，直到被通知（signal/signalAll）、中断或超时 signal()：唤醒一个等待在Condition上的线程，将该线程从等待队列中转移到同步队列中 signalAll()：能够唤醒所有等待在Condition上的线程 13.ThreadLocal 在多线程访问共享资源时会采取一定的线程同步方式（如：加锁）来解决带来的并发问题。（如图） 使用ThreadLocal对共享资源的访问也可以解决并发问题 **作用：**ThreadLocal提供了线程的本地变量，即当创建一个变量后，每个线程对其进行访问的时候访问的是自己线程的变量。 这里的本地内存并不是线程的工作内存，而是Thread类中的一个变量，而不是放在不是存放在ThreadLocal实例里面 这样做的好处： 线程安全，可以避免多线程访问同一个共享变量导致的并发问题。 不需要加锁，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。 原理 ThreadLocalMap 前面提到：每个线程的本地变量是放在调用线程Thread类中的一个变量threadLocals中，而不是放在不是存放在ThreadLocal实例里面 ThreadLocal是基于每个线程对象内部的一个叫做threadLocals的属性来实现的，它的类型是ThreadLocalMap（说白了就是一个Map对象）。它以ThreadLocal本本身作为键值（注意：这里的引用为弱引用），副本对象作为value存储，这样当每个线程调用该对象时就可以直接从自身的threadLocals属性中获取变量副本来进行操作。 为什么要用map？ 这是因为在实际使用中可能会有多个ThreadLocal变量，因此需要将这些ThreadLocal添加到map中。 为什么要设置为弱引用？ 如果为强引用： 由于ThreadLocalMap是属于线程的，而我们创建多线程时一般是使用线程池进行创建，线程池中的部分线程在任务结束后是不会关闭的，那么这部分线程中的ThreadLocalMap将会一直持有对ThreadLocal对象的强引用，导致ThreadLocal对象无法被垃圾回收，从而造成内存泄漏。 因此设置为弱引用：在下一次垃圾回收时，无论内存空间是否足够，只有弱引用指向的对象都会被直接回收。所以将ThreadLocalMap对ThreadLocal对象的引用设置成弱引用，就能避免ThreadLocal对象无法回收导致内存泄漏的问题。 内存泄露解决 解决：在finally中remove即可。 14.线程间异步传参 使用阿里开源的TransmittableThreadLocal（TTL） 详见官网：https://gitcode.net/mirrors/alibaba/transmittable-thread-local?utm_source=csdn_github_accelerator 15.进程间的通信方式 管道 消息队列 共享内存 消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。 现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程A和 进程B的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去， 大大提高了进程间通信的速度。 信号量 为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据 信号 信号一般用于一些异常情况下的进程间通信，是一种异步通信，它的数据结构一般就是一个数字。 socket 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要Socket通信了。 实际上，Socket通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。 16.其他问题 内核态和用户态的区别 内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。 用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。 **string stringbuffer stringbuilder的区别，各自的使用场景 ** 1、String是一个final类，代表不可变的字符序列，也就是String引用的字符串是不能改变的 2、StringBuffer/StringBuilder表示的字符串对象可以直接进行修改，而且方法也一样 3、StringBuilder是java5中引入的，和StringBuffer的方法完全相同。区别在与它是单线程环境下使用的，因为他的所有方法都没有synchronized修饰，他的效率理论上比StringBuffer要高 类 字符序列类型 效率 线程是否安全 String 不可变字符序列 效率低，但是复用率高 StringBuffer 可变字符序列 效率较高（在增删情况下） 安全 StringBuilder 可变字符序列 效率最高 不安全 ​ 任务事件中 如何保障多线程情况下线程安全的进行上层的writeAndFlush？ synchronized方法 加锁机制（ReentrantLock等） 使用Atomic对象 使用无状态对象（同样的输入返回一致的结果） 使用不可变对象（final）","categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"}],"tags":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/tags/java/"},{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/tags/juc/"}]},{"title":"javase","slug":"javase","date":"2023-02-17T12:58:55.387Z","updated":"2023-02-17T13:01:44.155Z","comments":true,"path":"2023/02/17/javase/","link":"","permalink":"http://cloud-tour.github.io/2023/02/17/javase/","excerpt":"","text":"1.equals和hashcode的区别 在Java中任何一个对象都具备equals(Object obj)和hashCode()这两个方法，因为他们是在Object类中定义的。 equals(Object obj)方法用来判断两个对象是否“相同”，如果“相同”则返回true，否则返回false。 hashCode()方法返回一个int数，在Object类中的默认实现是“将该对象的内部地址转换成一个整数返回”。 如果只重写equals不重写hashcode会有问题吗？ 会有问题，如果我们想按照其他规则来判断两个对象相等与否，此时只重写equals而不重写hashcode，那么在将数据存储入set、list等散列表中时，java会默认采用目标地址进行hashcode，这是，我们认为的两个相同的对象就可能放入不同的数组位置上了，这样就造成了数据的不唯一性。 补充： 当集合要添加新的元素时，可分为两个步骤： 先调用这个元素的 hashCode 方法，然后根据所得到的值计算出元素应该在数组的位置。如果这个位置上没有元素，那么直接将它存储在这个位置上； 如果这个位置上已经有元素了，那么调用它的equals方法与新元素进行比较：相同的话就不存了，否则，将其存在这个位置对应的链表中（Java 中 HashSet, HashMap 和 Hashtable的实现总将元素放到链表的表头）。 2.树 二叉搜索树（二叉查找树） 二叉查找树具有的特性： 左子树上所有结点的值均小于或等于它的根结点的值。 右子树上所有结点的值均大于或等于它的根结点的值。 左、右子树也分别为二叉排序树。 二叉平衡树（ALV） 什么是二叉平衡树呢？ 1.具有二叉查找树的全部特性。 2.每个节点的左子树和右子树的高度差至多为1。 平衡树基于这种特点就可以保证不会出现大量节点偏向于一边的情况了!（插入或者删除时，会发生左旋、右旋操作，使这棵树再次左右保持一定的平衡) 为什么有了平衡树还需要红黑树呢？ 虽然平衡树解决了二叉查找树退化为近似链表的缺点，能够把查找时间控制在O(logn)，不过却不是最佳的。 因为平衡树要求每个节点的左子树和右子树的高度差至多等于1，这个要求实在是太严了，导致每次进行插入删除节点的时候几乎都会破坏平衡树的第二个规则，进而我们都需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。 显然，如果在那种插入、删除很频繁的场景中，平衡树需要频繁着进行调整，这会使平衡树的性能大打折扣，为了解决这个问题，于是有了红黑树! 红黑树 红黑树一种自平衡的二叉查找树。除了具有二叉查找的特性外，还具有的特性： 节点是红色或黑色。 根节点是黑色。 每个叶子节点都是黑色的空节点(NIL节点)。 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 hashmap为什么不使用AVL树而使用红黑树？ 红黑树和AVL树都是最常用的平衡二叉搜索树，它们的查找、删除、修改都是O(lgn) time AVL树和红黑树有几点比较和区别： （1）AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。 （2）红黑树更适合于插入修改密集型任务。 （3）通常，AVL树的旋转比红黑树的旋转更加难以平衡和调试。 在CurrentHashMap中是加锁了的，实际上是读写锁，如果写冲突就会等待， 如果插入时间过长必然等待时间更长，而红黑树相对AVL树他的插入更快！ 3.java异常体系 java异常体系 Thorwable类（表示可抛出）是所有异常和错误的超类，两个直接子类为Error和Exception，分别表示错误和异常。 其中异常类Exception又分为运行时异常(RuntimeException)和非运行时异常， 这两种异常有很大的区别，也称之为不检查异常（Unchecked Exception）和检查异常（Checked Exception）。 Error与Exception Error错误：（这种错误无法处理）描述了Java运行时系统的内部错误和资源耗尽错误。一般是指虚拟机（JVM）相关的问题，如系统崩溃，虚拟机出错误等，这种错误无法恢复或不可能捕获，将导致应用程序中断，通常不处理。因为如果出现这样的内部错误，除了通告用户，并尽力使程序安全地终止之外，再也无能为力了。 Exception异常：Java的异常分为两种，checked Exception（编译时异常也叫非运行时异常）和 RuntimeException（运行时异常）。 运行时异常与非运行时异常 运行时异常（逻辑方面）都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。 非运行时异常（程序语法）是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。 Java异常处理方法有 抛出异常，捕捉异常。主要依赖于try、catch、finally、throw、throws五个关键字。 4.面向对象 面向对象理解 面向对象是模型化的，你只需抽象出一个类，这是一个封闭的盒子，在这里你拥有数据也拥有解决问题的方法。需要什么功能直接使用就可以了，不必去一步一步的实现，至于这个功能是如何实现的，管我们什么事？我们会用就 可以了。 面向对象的底层其实还是面向过程，把面向过程抽象成类，然后封装，方便我们使用的就是面向对象了。 面向过程理解 面向过程是具体化的，流程化的，解决一个问题，你需要一步一步的分析，一步一步的实现。 面向对象和面向过程的区别 面向过程 优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、 嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。 缺点：没有面向对象易维护、易复用、易扩展 面向对象 优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出 低耦合的系统，使系统更加灵活、更加易于维护 缺点：性能比面向过程低 5.接口与抽象类 成员区别 抽象类 构造方法：有构造方法，用于子类实例化使用。 成员变量：可以是变量，也可以是常量。 成员方法：可以是抽象的，也可以是非抽象的。 接口 构造方法：没有构造方法 成员变量：只能是常量。默认修饰符：public static final 成员方法：jdk1.7只能是抽象的。默认修饰符：public abstract (推荐：默认修饰符请自己永远手动给出) jdk1.8可以写以default和static开头的具体方法 类与接口的关系区别 类与类 继承关系,只能单继承。可以多层继承。 类与接口 实现关系,可以单实现,也可以多实现。 类还可以在继承一个类的同时实现多个接口。 接口与接口 继承关系,可以单继承,也可以多继承。 体现的理念不同 抽象类里面定义的都是一个继承体系中的共性内容。 接口是功能的集合,是一个体系额外的功能，是暴露出来的规则。 选择抽象类还是接口的依据 当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。 抽象类的功能要远超过接口，但是，定义抽象类的代价高。因为高级语言来说（从实际设计上来说也是）每个类只能继承一个类。在这个类中，你必须继承或编写出其所有子类的所有共性。虽然接口在功能上会弱化许多，但是它只是针对一个动作的描述。而且你可以在一个类中同时实现多个接口。在设计阶段会降低难度。 6.静态变量和普通变量的区别 所属目标不同 静态变量属于类的变量，普通变量属于对象的变量。 存储区域不同 静态变量存储在方法区的静态区，普通变量存储在堆区。 加载时间不同 静态变量是随时类的加载而加载的，随着类的消失而消失。 普通变量是随着对象的加载而加载，随着对象的消失而消失。 调用方式不同 静态变量只能通过类名，对象调用。 普通变量只能通过对象调用。 static可以修饰局部变量么？ 不能是局部变量，可以是内部类，全局变量，方法，代码块。 7.有了int为什么还要Integer 主要是因为面向对象的思想，因为Java语言是面向对象的，这也是它只所以流行的原因之一，对象封装有很多好处，可以把属性也就是数据跟处理这些数据的方法结合在一起，比如Integer就有parseInt()等方法来专门处理int型相关的数据， 另一个非常重要的原因就是在Java中绝大部分方法或类都是用来处理类类型对象的，如ArrayList集合类就只能以类作为他的存储对象，而这时如果想把一个int型的数据存入list是不可能的，必须把它包装成类，也就是Integer才能被List所接受。所以Integer的存在是很必要的。 8.Java泛型的好处及底层原理 泛型好处 保证了类型的安全性，泛型可以使编译器知道一个对象的限定类型是什么，这样编译器就可以在一个高的程度上验证这个类型 消除了强制类型转换 使得代码可读性好，减少了很多出错的机会 泛型的好处是在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率。 避免了不必要的装箱、拆箱操作，提高程序的性能 实现原理 泛型的实现是靠类型擦除技术 类型擦除是在编译期完成的 也就是在编译期 编译器会将泛型的类型参数都擦除成它的限定类型，如果没有则擦除为object类型之后在获取的时候再强制类型转换为对应的类型。 如果构建泛型实例时使用了泛型语法，那么编译器将标记该实例并关注该实例后续所有方法的调用，每次调用前都进行安全检查，非指定类型的方法都不能调用成功。 9.java定时器实现 使用Timer和和TimerTask类 1、Timer和TimerTask是java.util包下的类，用于实现定时任务 步骤1：创建TimerTask定时器任务，可以通过匿名内部类的方式创建 步骤2：创建Timer定时器，调用定时器的方法执行定时器任务 2、Timer的两个方法schedule()和scheduleAtFixedRate()及其重载方法： void schedule(TimerTask task, long delay)：在指定时间后执行1次任务，其中delay表示时延，单位是毫秒，设置为1000，则表示1秒后执行一次定时器任务； void schedule(TimerTask task, long delay, long period)：指定延迟指定时间后周期性地执行任务（delay毫秒后，每period毫秒执行一次） void scheduleAtFixedRate(TimerTask task, long delay, long period)：指定延迟指定时间后周期性地执行任务（delay毫秒后，每period毫秒执行一次） void scheduleAtFixedRate(TimerTask task, Date firstTime,long period) ：从指定日期firstTime开始，每period毫秒执行一次任务 案例： 12345678910111213141516171819public class TimerExample &#123; public static void main(String[] args) &#123; // 创建定时器 Timer timer = new Timer(); // 创建定时器任务 TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;Hello world!&quot;); &#125; &#125;; timer.schedule(timerTask, 1000); // 1秒后执行一次 timer.schedule(timerTask, 2000, 2000); // 两秒后每两秒执行一次 timer.scheduleAtFixedRate(timerTask, 3000, 3000); // 3秒后每3秒执行一次 timer.scheduleAtFixedRate(task, new Date(), 4000); // 每4秒执行一次 &#125; &#125; 使用线程池 案例： 1234567891011121314151617public class TimerExample &#123; public static void main(String[] args) &#123; // 创建定时器任务 TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;Hello world!&quot;); &#125; &#125;; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(2); scheduledThreadPool.schedule(timerTask, 1000, TimeUnit.MILLISECONDS); scheduledThreadPool.scheduleAtFixedRate(timerTask, 1000, 1000, TimeUnit.MILLISECONDS); &#125; &#125; 使用Spring Task 步骤1：在springBoot启动类上添加@EnableScheduling注解 12345678@EnableScheduling@SpringBootApplicationpublic class SpringbootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootApplication.class, args); &#125;&#125; 步骤2：创建一个定时任务类的bean，在类的方法上使用@Schedule注解，通过注解的cron属性设置定时器的属性 12345678@Componentpublic class TimerTask &#123; @Scheduled(cron = &quot;0 7 2 26 7 *&quot;) public void task() &#123; System.out.println(&quot;定时任务...&quot;); &#125;&#125; 以上代码指定在2022年7月26日02:07:00执行一次定时任务 通过Quartz任务调度工具 步骤1：在pom.xml中添加quartz的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; 步骤2：创建quartz的配置类 1234567891011121314151617181920212223242526272829@Configurationpublic class QuartzConfig &#123; // 创建一个JobDetail(工作详情)类对象,保存到Spring容器中，这个类用于封装我们编写的job接口实现类 @Bean public JobDetail jobDetail()&#123; System.out.println(&quot;showTime方法运行&quot;); return JobBuilder.newJob(QuartzJob.class) // 绑定要运行的任务类的类对象 .withIdentity(&quot;job&quot;) // 设置job的名称 .storeDurably() // 信息持久 // 设置storeDurably之后,当没有触发器指向这个JobDetail时,JobDetail也不会从 // Spring容器中删除,如果不设置这行,就会自动从Spring容器中删除 .build(); &#125; // 声明触发器，触发器决定我们的工作\\任务何时触发@Beanpublic Trigger trigger()&#123; System.out.println(&quot;showTime触发器运行&quot;); // 定义Cron表达式，每分钟触发一次 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(&quot;0/10 * * * * ?&quot;); return TriggerBuilder.newTrigger() .forJob(jobDetail()) // 绑定JobDetail对象 .withIdentity(&quot;trigger&quot;) // 定义触发器名称 .withSchedule(cronScheduleBuilder) // 绑定Cron表达式 .build();&#125; } 步骤:3：定义Job 1234567public class QuartzJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) &#123; // 输出当前时间 System.out.println(LocalDateTime.now()); &#125;&#125; 10.java中有哪些队列 Java 中的队列可以从不同的维度进行分类，例如可以从阻塞和非阻塞进行分类，也可以从有界和无界进行分类，而这里将从队列的功能上进行分类，例如：优先队列、普通队列、双端队列、延迟队列等。 普通队列 普通队列（Queue）是指实现了先进先出的基本队列，例如 ArrayBlockingQueue 和 LinkedBlockingQueue，其中 ArrayBlockingQueue 是用数组实现的普通队列，而 LinkedBlockingQueue 是使用链表实现的普通队列 双端队列 双端队列（Deque）是指队列的头部和尾部都可以同时入队和出队的数据结构。例如：LinkedBlockingDeque 优先队列 优先队列（PriorityQueue）是一种特殊的队列，它并不是先进先出的，而是优先级高的元素先出队。 优先队列是根据二叉堆实现的，二叉堆的数据结构如下图所示： 二叉堆分为两种类型：一种是最大堆一种是最小堆。以上展示的是最大堆，在最大堆中，任意一个父节点的值都大于等于它左右子节点的值。 因为优先队列是基于二叉堆实现的，因此它可以将优先级最好的元素先出队。 优先队列的出队是不考虑入队顺序的，它始终遵循的是优先级高的元素先出队。 延迟队列 延迟队列（DelayQueue）是基于优先队列 PriorityQueue 实现的，它可以看作是一种以时间为度量单位的优先的队列，当入队的元素到达指定的延迟时间之后方可出队。 其他队列（例如SynchronousQueue同步移交队列） 在 Java 的队列中有一个比较特殊的队列 SynchronousQueue，它的特别之处在于它内部没有容器，每次进行 put() 数据后（添加数据），必须等待另一个线程拿走数据后才可以再次添加数据 11.获取类中私有属性 通过反射获得 1234567891011121314//获取学生类的字节码对象Class clazzClass=Class.forName(&quot;com.test2.Student&quot;);//获取学生对象Object stuObject=clazzClass.newInstance();//获取私有的字段对象Field field=clazzClass.getDeclaredField(&quot;nameString&quot;);field.setAccessible(true);//设置发射时取消Java的访问检查，暴力访问System.out.println(field);field.set(stuObject, &quot;桂贤松&quot;);System.out.println(stuObject);//获取的是地址//使其获取到值Object nameObject=field.get(stuObject);System.out.println(nameObject); 12.分布式事务 满足ACID（原子性、一致性、隔离性、持久性）的一组操作，可以被称为一个事务。随着计算机系统的发展，越来越多的采用分布式的架构来对外提供服务，但是，不同的机器的处理性能、存储性能、网络状态等各有不同，让分布式集群始终对外提供可用的一致性服务一直是需要处理的问题。 为了保证数据变更请求在整个分布式环境下正确地执行，不会导致部分服务器暂时崩溃导致整个集群提供的服务和数据不再相同，在整个分布式系统处理数据变更请求的过程中，需要引入分布式事务的概念。常见的提交方式有二阶段提交（Two-phase Commit，2PC）和三阶段提交（Three-phase commit，3PC）。 二阶段提交 2PC，两阶段提交，将事务的提交过程分为资源准备和资源提交两个阶段，并且由事务协调者来协调所有事务参与者，如果准备阶段所有事务参与者都预留资源成功，则进行第二阶段的资源提交，否则事务协调者回滚资源。 第一阶段： 在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。 在接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。 当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。 第二阶段： 在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。 接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。 当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。 以上所描述的是XA两阶段提交的正向流程，接下来我们看一看失败情况的处理流程： 第一阶段： 第二阶段： 在XA的第一阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚。 于是在第二阶段，事务协调节点向所有的事务参与者发送Abort请求。接收到Abort请求之后，各个事务参与者节点需要在本地进行事务的回滚操作，回滚操作依照Undo Log来进行。 两阶段提交的不足 1.性能问题 XA协议遵循强一致性。在事务执行过程中，各个节点占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。 2.协调者单点故障问题 事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。 3.丢失消息导致的不一致问题。 在XA协议的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。 二阶段无法解决的问题 协调者在发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了，那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 三阶段提交 3PC，三阶段提交协议，是二阶段提交协议的改进版本，三阶段提交有两个改动点： （1）在协调者和参与者中都引入超时机制 （2）在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 所以3PC会分为3个阶段，CanCommit 准备阶段、PreCommit 预提交阶段、DoCommit 提交阶段，处理流程如下： 1、阶段一：CanCommit 准备阶段 ​ 协调者向参与者发送 canCommit 请求，参与者如果可以提交就返回Yes响应，否则返回No响应，具体流程如下： （1）事务询问：协调者向所有参与者发出包含事务内容的 canCommit 请求，询问是否可以提交事务，并等待所有参与者答复。 （2）响应反馈：参与者收到 canCommit 请求后，如果认为可以执行事务操作，则反馈 yes 并进入预备状态，否则反馈 no。 2、阶段二：PreCommit 阶段 ​ 协调者根据参与者的反应情况来决定是否可以进行事务的 PreCommit 操作。根据响应情况，有以下两种可能： （1）执行事务： 假如所有参与者均反馈 yes，协调者预执行事务，具体如下： ① 发送预提交请求：协调者向参与者发送 PreCommit 请求，并进入准备阶段 ② 事务预提交 ：参与者接收到 PreCommit 请求后，会执行本地事务操作，并将 undo 和 redo 信息记录到事务日志中（但不提交事务） ③ 响应反馈 ：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 （2）中断事务： 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断，流程如下： ① 发送中断请求 ：协调者向所有参与者发送 abort 请求。 ② 中断事务 ：参与者收到来自协调者的 abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。 3、阶段三：doCommit阶段 该阶段进行真正的事务提交，也可以分为以下两种情况： （1）提交事务： ① 发送提交请求：协调接收到所有参与者发送的ACK响应，那么他将从预提交状态进入到提交状态，并向所有参与者发送 doCommit 请求 ② 本地事务提交：参与者接收到doCommit请求之后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源 ③ 响应反馈：事务提交完之后，向协调者发送ack响应。 ④ 完成事务：协调者接收到所有参与者的ack响应之后，完成事务。 （2）中断事务： 任何一个参与者反馈 no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务 ① 发送中断请求：如果协调者处于工作状态，向所有参与者发出 abort 请求 ② 事务回滚：参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 ③ 反馈结果：参与者完成事务回滚之后，向协调者反馈ACK消息 ④ 中断事务：协调者接收到参与者反馈的ACK消息之后，执行事务的中断。 进入doCommit阶段后，无论协调者出现问题，或者协调者与参与者之间的网络出现问题，都会导致参与者无法接收到协调者发出的 doCommit 请求或 abort 请求。此时，参与者都会在等待超时之后，继续执行事务提交。这其实基于概率来决定的，当进入第三阶段时，说明第一阶段收到所有参与者的CanCommit响应都是Yes，意味着大家都同意修改了，并且第二阶段所有的参与者对协调者的PreCommit请求也都是同意的。所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 3PC的优缺点： 与2PC相比，3PC降低了阻塞范围，并且在等待超时后，协调者或参与者会中断事务，避免了协调者单点问题，阶段三中协调者出现问题时，参与者会继续提交事务。 ​ 数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 doCommit 指令时，此时如果协调者请求中断事务，而协调者因为网络问题无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。 12PC和3PC都无法保证数据绝对的一致性，一般为了预防这种问题，可以添加一个报警，比如监控到事务异常的时候，通过脚本自动补偿差异的信息。 TTC 1、什么是TCC： TCC（Try Confirm Cancel）是应用层的两阶段提交，所以对代码的侵入性强，其核心思想是：针对每个操作，都要实现对应的确认和补偿操作，也就是业务逻辑的每个分支都需要实现 try、confirm、cancel 三个操作，第一阶段由业务代码编排来调用Try接口进行资源预留，当所有参与者的 Try 接口都成功了，事务协调者提交事务，并调用参与者的 confirm 接口真正提交业务操作，否则调用每个参与者的 cancel 接口回滚事务，并且由于 confirm 或者 cancel 有可能会重试，因此对应的部分需要支持幂等。 2、TCC的执行流程： ​ TCC的执行流程可以分为两个阶段，分别如下： （1）第一阶段：Try，业务系统做检测并预留资源 (加锁，锁住资源)，比如常见的下单，在try阶段，我们不是真正的减库存，而是把下单的库存给锁定住。 （2）第二阶段：根据第一阶段的结果决定是执行confirm还是cancel Confirm：执行真正的业务（执行业务，释放锁） Cancle：是对Try阶段预留资源的释放（出问题，释放锁） 3、TCC如何保证最终一致性： TCC 事务机制以 Try 为中心的，Confirm 确认操作和 Cancel 取消操作都是围绕 Try 而展开。因此，Try 阶段中的操作，其保障性是最好的，即使失败，仍然有 Cancel 取消操作可以将其执行结果撤销。 Try阶段执行成功并开始执行 Confirm 阶段时，默认 Confirm 阶段是不会出错的，也就是说只要 Try 成功，Confirm 一定成功（TCC设计之初的定义） Confirm 与 Cancel 如果失败，由TCC框架进行重试补偿存在极低概率在CC环节彻底失败，则需要定时任务或人工介入 4、TCC的注意事项： （1）允许空回滚： 空回滚出现的原因是 Try 超时或者丢包，导致 TCC 分布式事务二阶段的 回滚，触发 Cancel 操作，此时事务参与者未收到Try，但是却收到了Cancel 请求。 所以 cancel 接口在实现时需要允许空回滚，也就是 Cancel 执行时如果发现没有对应的事务 xid 或主键时，需要返回回滚成功，让事务服务管理器认为已回滚。 （2）防悬挂控制： 悬挂指的是二阶段的 Cancel 比 一阶段的Try 操作先执行，出现该问题的原因是 Try 由于网络拥堵而超时，导致事务管理器生成回滚，触发 Cancel 接口，但之后拥堵在网络的 Try 操作又被资源管理器收到了，但是 Cancel 比 Try 先到。但按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，所以此时应该拒绝执行空回滚之后到来的 Try 操作，否则会产生数据不一致。因此我们可以在 Cancel 空回滚返回成功之前，先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口执行前先检查这条事务xid或业务主键是否已经标记为回滚成功，如果是则不执行 Try 的业务操作。 （3）幂等控制： 由于网络原因或者重试操作都有可能导致 Try - Confirm - Cancel 3个操作的重复执行，所以使用 TCC 时需要注意这三个操作的幂等控制，通常我们可以使用事务 xid 或业务主键判重来控制。 5、TCC方案的优缺点： （1）TCC 事务机制相比于上面介绍的 XA 事务机制，有以下优点： 性能提升：具体业务来实现，控制资源锁的粒度变小，不会锁定整个资源。 数据最终一致性：基于 Confirm 和 Cancel 的幂等性，保证事务最终完成确认或者取消，保证数据的一致性。 可靠性：解决了 XA 协议的协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动管理器也变成多点，引入集群。 （2）缺点 TCC 的 Try、Confirm 和 Cancel 操作功能要按具体业务来实现，业务耦合度较高，提高了开发成本。 Saga事务 1、什么是Saga事务： ​ Saga 事务核心思想是将长事务拆分为多个本地短事务并依次正常提交，如果所有短事务均执行成功，那么分布式事务提交；如果出现某个参与者执行本地事务失败，则由 Saga 事务协调器协调根据相反顺序调用补偿操作，回滚已提交的参与者，使分布式事务回到最初始的状态。Saga 事务基本协议如下： （1）每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。 （2）每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。 与TCC事务补偿机制相比，TCC有一个预留(Try)动作，相当于先报存一个草稿，然后才提交；Saga事务没有预留动作，直接提交。 2、Saga的恢复策略： 对于事务异常，Saga提供了两种恢复策略，分别如下： （1）向后恢复(backward recovery)： 当执行事务失败时，补偿所有已完成的事务，是“一退到底”的方式，这种做法的效果是撤销掉之前所有成功的子事务，使得整个 Saga 的执行结果撤销。如下图： 从上图可知事务执行到了支付事务T3，但是失败了，因此事务回滚需要从C3,C2,C1依次进行回滚补偿，对应的执行顺序为：T1,T2,T3,C3,C2,C1。 （2）向前恢复(forward recovery)： ​ 对于执行不通过的事务，会尝试重试事务，这里有一个假设就是每个子事务最终都会成功，这种方式适用于必须要成功的场景，事务失败了重试，不需要补偿。流程如下图： 3、Saga事务的实现方式： Saga事务有两种不同的实现方式，分别如下： 命令协调（Order Orchestrator） 事件编排（Event Choreographyo） （1）命令协调： ​ 中央协调器（Orchestrator，简称 OSO）以命令/回复的方式与每项服务进行通信，全权负责告诉每个参与者该做什么以及什么时候该做什么。整体流程如下图： ① 事务发起方的主业务逻辑请求 OSO 服务开启订单事务 ② OSO 向库存服务请求扣减库存，库存服务回复处理结果。 ③ OSO 向订单服务请求创建订单，订单服务回复创建结果。 ④ OSO 向支付服务请求支付，支付服务回复处理结果。 ⑤ 主业务逻辑接收并处理 OSO 事务处理结果回复。 ​ 中央协调器 OSO 必须事先知道执行整个事务所需的流程，如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚，基于中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。 （2）事件编排： ​ 命令协调方式基于中央协调器实现，所以有单点风险，但是事件编排方式没有中央协调器。事件编排的实现方式中，每个服务产生自己的时间并监听其他服务的事件来决定是否应采取行动。 ​ 在事件编排方法中，第一个服务执行一个事务，然后发布一个事件，该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。 ① 事务发起方的主业务逻辑发布开始订单事件。 ② 库存服务监听开始订单事件，扣减库存，并发布库存已扣减事件。 ③ 订单服务监听库存已扣减事件，创建订单，并发布订单已创建事件。 ④ 支付服务监听订单已创建事件，进行支付，并发布订单已支付事件。 ⑤ 主业务逻辑监听订单已支付事件并处理。 如果事务涉及 2 至 4 个步骤，则非常合适使用事件编排方式，它是实现 Saga 模式的自然方式，它很简单，容易理解，不需要太多的代码来构建。 4、Saga事务的优缺点： （1）命令协调设计的优缺点： ① 优点： 服务之间关系简单，避免服务间循环依赖，因为 Saga 协调器会调用 Saga 参与者，但参与者不会调用协调器。 程序开发简单，只需要执行命令/回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。 易维护扩展，在添加新步骤时，事务复杂性保持线性，回滚更容易管理，更容易实施和测试。 ② 缺点： 中央协调器处理逻辑容易变得庞大复杂，导致难以维护。 存在协调器单点故障风险。 （2）事件编排设计的优缺点： ① 优点： 避免中央协调器单点故障风险。 当涉及的步骤较少服务开发简单，容易实现。 ② 缺点： 服务之间存在循环依赖的风险。 当涉及的步骤较多，服务间关系混乱，难以追踪调测。 1由于 Saga 模型没有 Prepare 阶段，因此事务间不能保证隔离性。当多个 Saga 事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如：在应用层面加锁，或者应用层面预先冻结资源。 本地消息表 1、什么是本地消息表： 本地消息表的核心思路就是将分布式事务拆分成本地事务进行处理，在该方案中主要有两种角色：事务主动方和事务被动方。事务主动发起方需要额外新建事务消息表，并在本地事务中完成业务处理和记录事务消息，并轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。 ​ 这样可以避免以下两种情况导致的数据不一致性： 业务处理成功、事务消息发送失败 业务处理失败、事务消息发送成功 2、本地消息表的执行流程： ① 事务主动方在同一个本地事务中处理业务和写消息表操作 ② 事务主动方通过消息中间件，通知事务被动方处理事务消息。消息中间件可以基于 Kafka、RocketMQ 消息队列，事务主动方主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。 ③ 事务被动方通过消息中间件，通知事务主动方事务已处理的消息。 ④ 事务主动方接收中间件的消息，更新消息表的状态为已处理。 一些必要的容错处理如下： 当①处理出错，由于还在事务主动方的本地事务中，直接回滚即可 当②、③处理出错，由于事务主动方本地保存了消息，只需要轮询消息重新通过消息中间件发送，通知事务被动方重新读取消息处理业务即可。 如果是业务上处理失败，事务被动方可以发消息给事务主动方回滚事务 如果事务被动方已经消费了消息，事务主动方需要回滚事务的话，需要发消息通知事务主动方进行回滚事务。 3、本地消息表的优缺点： （1）优点： 从应用设计开发的角度实现了消息数据的可靠性，消息数据的可靠性不依赖于消息中间件，弱化了对 MQ 中间件特性的依赖。 方案轻量，容易实现。 （2）缺点： 与具体的业务场景绑定，耦合性强，不可公用 消息数据与业务数据同库，占用业务系统资源 业务系统在使用关系型数据库的情况下，消息服务性能会受到关系型数据库并发性能的局限 ## MQ事务消息 1、MQ事务消息的执行流程： ​ 基于MQ的分布式事务方案本质上是对本地消息表的封装，整体流程与本地消息表一致，唯一不同的就是将本地消息表存在了MQ内部，而不是业务数据库中，如下图： ​ 由于将本地消息表存在了MQ内部，那么MQ内部的处理尤为重要，下面主要基于 RocketMQ4.3 之后的版本介绍 MQ 的分布式事务方案 2、RocketMQ事务消息： ​ 在本地消息表方案中，保证事务主动方发写业务表数据和写消息表数据的一致性是基于数据库事务，而 RocketMQ 的事务消息相对于普通 MQ提供了 2PC 的提交接口，方案如下： （1）正常情况： 在事务主动方服务正常，没有发生故障的情况下，发消息流程如下： 步骤①：发送方向 MQ Server(MQ服务方)发送 half 消息 步骤②：MQ Server 将消息持久化成功之后，向发送方 ack 确认消息已经发送成功 步骤③：发送方开始执行本地事务逻辑 步骤④：发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。 最终步骤：MQ Server 如果收到的是 commit 操作，则将半消息标记为可投递，MQ订阅方最终将收到该消息；若收到的是 rollback 操作则删除 half 半消息，订阅方将不会接受该消息 （2）异常情况： 在断网或者应用重启等异常情况下，图中的步骤④提交的二次确认超时未到达 MQ Server，此时的处理逻辑如下： 步骤⑤：MQ Server 对该消息发起消息回查 步骤⑥：发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果 步骤⑦：发送方根据检查得到的本地事务的最终状态再次提交二次确认。 最终步骤：MQ Server基于 commit/rollback 对消息进行投递或者删除。 3、MQ事务消息的优缺点： （1）优点：相比本地消息表方案，MQ 事务方案优点是： 消息数据独立存储 ，降低业务系统与消息系统之间的耦合 吞吐量大于使用本地消息表方案 （2）缺点： 一次消息发送需要两次网络请求(half 消息 + commit/rollback 消息) 。 业务处理服务需要实现消息状态回查接口。 最大努力通知 最大努力通知也称为定期校对，是对MQ事务方案的进一步优化。它在事务主动方增加了消息校对的接口，如果事务被动方没有接收到主动方发送的消息，此时可以调用事务主动方提供的消息校对的接口主动获取 ​ 在可靠消息事务中，事务主动方需要将消息发送出去，并且让接收方成功接收消息，这种可靠性发送是由事务主动方保证的；但是最大努力通知，事务主动方仅仅是尽最大努力（重试，轮询…）将事务发送给事务接收方，所以存在事务被动方接收不到消息的情况，此时需要事务被动方主动调用事务主动方的消息校对接口查询业务消息并消费，这种通知的可靠性是由事务被动方保证的。 ​ 所以最大努力通知适用于业务通知类型，例如微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口。 各方案常见使用场景 2PC/3PC：依赖于数据库，能够很好的提供强一致性和强事务性，但延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。 TCC：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。 本地消息表/MQ 事务：适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。 Saga 事务：由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。Saga 由于缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。所以，Saga 事务较适用于补偿动作容易处理的场景 13.其他 字符串数据结构在C语言的底层实现，是字节数组吗。 jdk1.8及以前String底层使用是char[]，1.9开始使用byte[] 原子变量的实现原理 底层用到都是cas，类中用了unsafe来实现cas Unsafe 对象提供了非常底层的，操作内存、线程的方法，Unsafe 对象不能直接调用，只能通过反射获得 有没有更好的计数器解决策略 LongAdder","categories":[{"name":"javase","slug":"javase","permalink":"http://cloud-tour.github.io/categories/javase/"}],"tags":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/tags/java/"}]},{"title":"debian系统下安装nginx","slug":"debian系统下安装nginx","date":"2022-10-08T04:14:18.807Z","updated":"2022-10-08T04:29:18.082Z","comments":true,"path":"2022/10/08/debian系统下安装nginx/","link":"","permalink":"http://cloud-tour.github.io/2022/10/08/debian%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85nginx/","excerpt":"","text":"​ 博主在工作学习时，经常性使用到nginx，但是某些时候有一些指令总是忘记，去网上收缩有甚是繁琐，因此用本篇博客记录安装的指令，与最后各种文件存放的位置 debian下安装nginx 在安装nginx之前，需要先安装一些插件，使得后面nginx能够正常运行 gcc 1apt install -y build-essential 正则库 1apt install -y libpcre3 libpcre3-dev zlib库 1apt install -y zlib1g-dev OpenSSL库 1apt install -y openssl libssl-dev 下载nginx源码 1234567891011# 下载源码wget http://nginx.org/download/nginx-1.20.2.tar.gz# 解压源码tar -xf nginx-1.20.2.tar.gz# 进入源代码内cd nginx-1.20.2 配置 1234567891011121314151617181920212223242526272829303132333435363738./configure \\--prefix=/usr/local/nginx \\--user=www \\--group=www \\--sbin-path=/usr/local/nginx/sbin/nginx \\--conf-path=/usr/local/nginx/nginx.conf \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--pid-path=/var/run/nginx.pid \\--lock-path=/var/run/nginx.lock \\--http-client-body-temp-path=/var/cache/nginx/client_temp \\--http-proxy-temp-path=/var/cache/nginx/proxy_temp \\--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\--http-scgi-temp-path=/var/cache/nginx/scgi_temp \\--with-file-aio \\--with-threads \\--with-http_addition_module \\--with-http_auth_request_module \\--with-http_dav_module \\--with-http_flv_module \\--with-http_gunzip_module \\--with-http_gzip_static_module \\--with-http_mp4_module \\--with-http_random_index_module \\--with-http_realip_module \\--with-http_secure_link_module \\--with-http_slice_module \\--with-http_ssl_module \\--with-http_stub_status_module \\--with-http_sub_module \\--with-http_v2_module \\--with-mail \\--with-mail_ssl_module \\--with-stream \\--with-stream_realip_module \\--with-stream_ssl_module \\--with-stream_ssl_preread_module 其中： --prefix：Nginx主要安装路径，后续Nginx子目录依照这个变量展开 --user：设置Nginx进程启动时，所属的用户 --group：设置Nginx进程启动时，所属的用户组 编译 1make 安装 1make install 创建systemctl守护，管理Nginx： 1vim /usr/lib/systemd/system/nginx.service 12345678910111213[Unit]Description=nginxAfter=network.target[Service]Type=forkingExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s quitPrivateTmp=true [Install]WantedBy=multi-user.target 启动各服务 123456789systemctl daemon-reload-------------------systemctl start nginx-------------------#观察nginx启动状态systemctl status nginx.service-------------------#查看80线程状态lsof -i:80 nginx命令 如果你是按我的方法编译，那么，需要注意。 /usr/local/nginx：为Nginx编译安装的地址。 /usr/local/nginx/conf/nginx.conf：Nginx默认配置文件。 同时，我们使用systemctl对Nginx进行管理： systemctl start nginx：启动Nginx服务。 systemctl reload nginx：Nginx配置重载。 systemctl stop nginx：停止Nginx服务。 本片文章参考https://www.php.cn/nginx/488924.html","categories":[{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"nginx","slug":"nginx","permalink":"http://cloud-tour.github.io/tags/nginx/"}]},{"title":"debian系统配置java11环境","slug":"debian系统配置java11环境","date":"2022-10-08T03:31:36.963Z","updated":"2022-10-08T03:47:19.584Z","comments":true,"path":"2022/10/08/debian系统配置java11环境/","link":"","permalink":"http://cloud-tour.github.io/2022/10/08/debian%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AEjava11%E7%8E%AF%E5%A2%83/","excerpt":"","text":"​ 博主最近在工作中使用到debian系统，在初始系统中要进行一些配置，使后续的程序能正常运行，因此用该篇文章记录一些配置的步骤。 博主用的debian系统为11.2版本 下载jdk11 分别输入下列两条指令 123apt search openjdk------------------------------sudo apt install default-jdk 输入查看java版本 1java -version 出现下列信息即为安装成功 其他操作 ​ 其实在上述操作后应该就可以正常运行java程序了，但是为了以防万一，再贴出其他操作 debian的系统环境变量 debian系统的环境变量位置位于/etc/profile 入若需要进行配置环境变量，直接vim即可 配置方式： ​ 配置环境变量时，需要先在windows中下载jdk11的安装包，然后传到debian的/etc/java中，再解压。具体信息步骤博主就不在这贴出了。自行百度，很简单的。","categories":[{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"java11","slug":"java11","permalink":"http://cloud-tour.github.io/tags/java11/"}]},{"title":"proteus8.9与keil4的简单使用","slug":"proteus8.9与keil4的简单使用","date":"2022-10-07T13:45:21.243Z","updated":"2022-10-07T14:28:39.430Z","comments":true,"path":"2022/10/07/proteus8.9与keil4的简单使用/","link":"","permalink":"http://cloud-tour.github.io/2022/10/07/proteus8.9%E4%B8%8Ekeil4%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","excerpt":"","text":"[toc] 最近博主在学51单片机，因此接触到proteus和keil，本篇文章简单介绍一下这两款软件的使用以及如何结合起来，并用这两款软件简单操作一个51单片机实现一个LED灯的闪烁操作。 keil4 ​ 对于keil4，简单来说就是用来写代码的，将代码编译后生成**.hex**文件，将此文件烧入单片机中便可驱动单片机实现某些特定的操作。 创建工程 新建项目 new一个project 选择Atmel下的AT89C51（即51单片机） 下面这个是提醒是否使用汇编，直接选择否，因为我们使用的是c语言 新建.c文件 接下来new一个file文件 ctrl+s保存为.c文件 将该c文件假如到project中 配置项目编译时自动生成.hex文件 编写功能代码 编写代码 下面写的代码是控制p2的0口间隔输出高低电平 1234567891011121314151617181920212223#include&quot;reg51.h&quot;//代表p2口的0处sbit LED0=P2^0;//睡眠函数void sleep(unsigned int n)&#123; unsigned int i = 0,j=0; for(i=0;i&lt;n;i++)&#123; for(j=0;j&lt;120;j++); &#125;&#125;void main()&#123; while(1)&#123; //输出低电平 LED0=0; sleep(5); //输出高电平 LED0=1; sleep(5); &#125;&#125; 写完编译 无error即可 观察项目路径，已生成,hex文件 proteus8.9 ​ 对于proteus来说，可简单理解为是一个用来对单片机仿真的软件，可以用.hex文件驱动单片机进行特定的功能并显现出来。 创建工程 new一个新的工程，不用选择什么，一直下一步直至完成 制作仿真图 添加元器件仓库 添加AT89C51 选中双击即可 同理添加RES和LED-BIBY 置放元器件（单击后即可在图中置放元器件）添加一个电源 连线 修改电阻值（电阻的值必须大于250，否则可能出错） 烧入程序 将.hex文件烧入程序中。双击单片机 烧入成功后即可仿真 end ​ 这样就利用proteus和keil完成一个简单的单片机电路，实现对led控制闪烁。","categories":[{"name":"51单片机","slug":"51单片机","permalink":"http://cloud-tour.github.io/categories/51%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"proteus","slug":"proteus","permalink":"http://cloud-tour.github.io/tags/proteus/"},{"name":"keil","slug":"keil","permalink":"http://cloud-tour.github.io/tags/keil/"}]}],"categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"},{"name":"javase","slug":"javase","permalink":"http://cloud-tour.github.io/categories/javase/"},{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"},{"name":"51单片机","slug":"51单片机","permalink":"http://cloud-tour.github.io/categories/51%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/tags/java/"},{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/tags/juc/"},{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"nginx","slug":"nginx","permalink":"http://cloud-tour.github.io/tags/nginx/"},{"name":"java11","slug":"java11","permalink":"http://cloud-tour.github.io/tags/java11/"},{"name":"proteus","slug":"proteus","permalink":"http://cloud-tour.github.io/tags/proteus/"},{"name":"keil","slug":"keil","permalink":"http://cloud-tour.github.io/tags/keil/"}]}