{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://Cloud-Tour.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-10-14T13:41:36.430Z","updated":"2022-10-06T02:48:58.718Z","comments":false,"path":"/404.html","permalink":"http://cloud-tour.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2022-10-06T02:48:58.720Z","updated":"2022-10-06T02:48:58.720Z","comments":false,"path":"about/index.html","permalink":"http://cloud-tour.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"友情链接","date":"2022-10-06T02:48:58.721Z","updated":"2022-10-06T02:48:58.721Z","comments":true,"path":"links/index.html","permalink":"http://cloud-tour.github.io/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-10-06T02:48:58.722Z","updated":"2022-10-06T02:48:58.722Z","comments":false,"path":"tags/index.html","permalink":"http://cloud-tour.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-10-06T02:48:58.721Z","updated":"2022-10-06T02:48:58.721Z","comments":false,"path":"categories/index.html","permalink":"http://cloud-tour.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-10-06T02:48:58.720Z","updated":"2022-10-06T02:48:58.720Z","comments":false,"path":"books/index.html","permalink":"http://cloud-tour.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-10-06T04:17:29.443Z","updated":"2022-10-06T02:48:58.722Z","comments":false,"path":"repository/index.html","permalink":"http://cloud-tour.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"AOP实现日志环绕通知","slug":"AOP实现日志环绕通知","date":"2023-04-13T09:21:11.292Z","updated":"2023-04-13T10:17:58.217Z","comments":true,"path":"2023/04/13/AOP实现日志环绕通知/","link":"","permalink":"http://cloud-tour.github.io/2023/04/13/AOP%E5%AE%9E%E7%8E%B0%E6%97%A5%E5%BF%97%E7%8E%AF%E7%BB%95%E9%80%9A%E7%9F%A5/","excerpt":"","text":"AOP实现日志环绕通知 通常在项目中，都会需要进行日志输出，本文介绍在java中利用AOP实现控制台日志环绕通知 下面演示方法为在springboot基础项目中演示（使用的是springAop和lombok） 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 该方式使用了Slf4j显示结果，所以添加lombok依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; 创建通知对象类 1234567891011121314151617181920212223@Data@EqualsAndHashCode(callSuper = false)public class WebLog &#123; //操作描述 private String description; //操作用户 private String username; //耗时 private Integer spendTime; //根路径 private String basePath; //URI private String uri; //URL private String url; //请求类型 private String method; //请求参数 private Object parameter; //返回结果 private Object result;&#125; 编写切面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@Component@Aspect@Order(1)@Slf4jpublic class WebLogAspect &#123; /** * 1 定义切入点 */ //第一个*表示匹配--任何访问修饰符+返回类 //第二个*表示fun.cloudtour.controller下的任意类 //第三个*表示所有方法 //...表示所有参数 @Pointcut(&quot;execution(* fun.cloudtour.controller.*.*(..))&quot;) public void webLog()&#123;&#125; /** * 2 记录日志的环绕通知 */ @Around(&quot;webLog()&quot;) public Object recodeWebLog(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; Object result = null ; WebLog webLog = new WebLog(); long start = System.currentTimeMillis() ; // 执行方法的真实调用 result = proceedingJoinPoint.proceed(proceedingJoinPoint.getArgs()); long end = System.currentTimeMillis() ; // 请求该接口花费的时间 webLog.setSpendTime((int)(start-end)/1000); // 获取当前请求的request对象 ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = requestAttributes.getRequest(); String url = request.getRequestURL().toString(); webLog.setUri(request.getRequestURI()); // 设置请求的uri webLog.setUrl(url); //添加根路径记录 http://ip:port/ webLog.setBasePath(StrUtil.removeSuffix(url, URLUtil.url(url).getPath())); // 获取方法 MethodSignature signature = (MethodSignature)proceedingJoinPoint.getSignature(); // 获取类的名称 String targetClassName = proceedingJoinPoint.getTarget().getClass().getName(); Method method = signature.getMethod(); // fun.cloudtour.controller.XXXController.XXX() webLog.setMethod(targetClassName+&quot;.&quot;+method.getName()); //&#123;&quot;key_参数的名称&quot;:&quot;value_参数的值&quot;&#125; webLog.setParameter(getMethodParameter(method,proceedingJoinPoint.getArgs())); webLog.setResult(result); log.info(JSON.toJSONString(webLog,true)); return result ; &#125; /** * 获取方法的执行参数 * @param method * @param args * @return * &#123;&quot;key_参数的名称&quot;:&quot;value_参数的值&quot;&#125; */ private Object getMethodParameter(Method method, Object[] args) &#123; Map&lt;String, Object&gt; methodParametersWithValues = new HashMap&lt;&gt;(); LocalVariableTableParameterNameDiscoverer localVariableTableParameterNameDiscoverer = new LocalVariableTableParameterNameDiscoverer(); // 方法的形参名称 String[] parameterNames = localVariableTableParameterNameDiscoverer.getParameterNames(method); //对于file类型不显示具体值 for (int i = 0; i &lt;parameterNames.length ; i++) &#123; if(parameterNames[i].equals(&quot;password&quot;) || parameterNames[i].equals(&quot;file&quot;))&#123; methodParametersWithValues.put(parameterNames[i],&quot;受限的支持类型&quot;) ; &#125;else&#123; methodParametersWithValues.put(parameterNames[i],args[i]) ; &#125; &#125; return methodParametersWithValues ; &#125;&#125; 编写Controller 注：必须在fun.cloudtour.controller包下创建才能使用上述切面 1234567891011@RestControllerpublic class TestController &#123; @PostMapping(&quot;/test/aspect&quot;) public String fileUpload(@RequestParam String name, @RequestParam String password)&#123; System.out.println(&quot;名字是&quot; + name); System.out.println(&quot;密码是&quot; + password); return &quot;fileUpload()执行成功&quot;; &#125;&#125; 测试 Slf4j环绕通知结果","categories":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/categories/java/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://cloud-tour.github.io/tags/AOP/"}]},{"title":"java使用阿里云oss文件上传","slug":"java使用阿里云oss文件上传","date":"2023-04-13T07:49:33.186Z","updated":"2023-04-14T08:58:27.429Z","comments":true,"path":"2023/04/13/java使用阿里云oss文件上传/","link":"","permalink":"http://cloud-tour.github.io/2023/04/13/java%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91oss%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0/","excerpt":"","text":"java使用阿里云oss文件上传 在很多时候，java开发系统的时候，经常会有存储文件的行为，而对于文件存储管理，目前最常用的手段就是利用网上各厂商的存储系统（例如阿里云oss、腾讯云cos对象存储服务等）或者自己在服务器上搭建文件存储系统（Minio等）。本文着重讲解在java代码中将文件上传到阿里云对象存储oss中的方式。对于其他方式进行的文件存储，大概实现方式大差不差，具体详见各厂商或存储系统的开发文档即可。 创建Bucket 首先需要在阿里云服务中创建出存储桶 进入阿里云官网，搜索oss，点击对象存储oss，创建bucket 创建bucket 获取访问密匙 获取访问密匙 得到AccessKey ID和AccessKey Secret 获取Endpoint地域节点 配置文件 在springboot中添加依赖 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alicloud-oss&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--code￼0--&gt; 测试 我使用的是apipost进行文件上传测试 上传成功 返回阿里云oss系统查看 上传成功","categories":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/categories/java/"}],"tags":[{"name":"文件存储","slug":"文件存储","permalink":"http://cloud-tour.github.io/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"}]},{"title":"java定时器实现","slug":"java定时器的实现方式","date":"2023-04-07T03:53:50.212Z","updated":"2023-04-10T12:03:09.587Z","comments":true,"path":"2023/04/07/java定时器的实现方式/","link":"","permalink":"http://cloud-tour.github.io/2023/04/07/java%E5%AE%9A%E6%97%B6%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/","excerpt":"","text":"java定时器实现 最近在做项目中发现有些模块需要用到定时任务，有时是一些简单的任务并不需要外部定时组件来协助，这时就要用到java中一些有定时功能的工具。本文介绍java中一些常用的定时方式。 使用Timer和TimerTask类 1、Timer和TimerTask是java.util包下的类，用于实现定时任务 步骤1：创建TimerTask定时器任务，可以通过匿名内部类的方式创建 步骤2：创建Timer定时器，调用定时器的方法执行定时器任务 2、Timer的两个方法schedule()和scheduleAtFixedRate()及其重载方法： void schedule(TimerTask task, long delay)：在指定时间后执行1次任务，其中delay表示时延，单位是毫秒，设置为1000，则表示1秒后执行一次定时器任务； void schedule(TimerTask task, long delay, long period)：指定延迟指定时间后周期性地执行任务（delay毫秒后，每period毫秒执行一次） void scheduleAtFixedRate(TimerTask task, long delay, long period)：指定延迟指定时间后周期性地执行任务（delay毫秒后，每period毫秒执行一次） void scheduleAtFixedRate(TimerTask task, Date firstTime,long period) ：从指定日期firstTime开始，每period毫秒执行一次任务 案例： 12345678910111213141516171819public class TimerExample &#123; public static void main(String[] args) &#123; // 创建定时器 Timer timer = new Timer(); // 创建定时器任务 TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;Hello world!&quot;); &#125; &#125;; timer.schedule(timerTask, 1000); // 1秒后执行一次 timer.schedule(timerTask, 2000, 2000); // 两秒后每两秒执行一次 timer.scheduleAtFixedRate(timerTask, 3000, 3000); // 3秒后每3秒执行一次 timer.scheduleAtFixedRate(task, new Date(), 4000); // 每4秒执行一次 &#125; &#125; 使用线程池 java中有个ScheduledExecutorService线程池能够执行定时任务。关于线程的使用，在我另一篇博客中有写到，本文就只写大概使用方式。 案例： 12345678910111213141516171819public class TimerExample &#123; public static void main(String[] args) &#123; // 创建定时器任务 TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; System.out.println(&quot;Hello world!&quot;); &#125; &#125;; //创建线程池 ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(2); //指示任务在1s后执行 scheduledThreadPool.schedule(timerTask, 1000, TimeUnit.MILLISECONDS); //每隔1s循环执行 scheduledThreadPool.scheduleAtFixedRate(timerTask, 1000, 1000, TimeUnit.MILLISECONDS); &#125; &#125; 使用Spring Task 步骤1：在springBoot启动类上添加@EnableScheduling注解 123456789//开启定时任务功能@EnableScheduling@SpringBootApplicationpublic class SpringbootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootApplication.class, args); &#125;&#125; 步骤2：创建一个定时任务类的bean，在类的方法上使用@Schedule注解，通过注解的cron属性设置定时器的属性（cron是一种表达式，可以指示定时时间） 12345678@Componentpublic class TimerTask &#123; @Scheduled(cron = &quot;0 7 2 26 7 *&quot;) public void task() &#123; System.out.println(&quot;定时任务...&quot;); &#125;&#125; 以上代码指定在2022年7月26日02:07:00执行一次定时任务 通过Quartz任务调度工具 步骤1：在pom.xml中添加quartz的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;&lt;/dependency&gt; 步骤2：创建quartz的配置类 1234567891011121314151617181920212223242526272829@Configurationpublic class QuartzConfig &#123; // 创建一个JobDetail(工作详情)类对象,保存到Spring容器中，这个类用于封装我们编写的job接口实现类 @Bean public JobDetail jobDetail()&#123; System.out.println(&quot;showTime方法运行&quot;); return JobBuilder.newJob(QuartzJob.class) // 绑定要运行的任务类的类对象 .withIdentity(&quot;job&quot;) // 设置job的名称 .storeDurably() // 信息持久 // 设置storeDurably之后,当没有触发器指向这个JobDetail时,JobDetail也不会从 // Spring容器中删除,如果不设置这行,就会自动从Spring容器中删除 .build(); &#125; // 声明触发器，触发器决定我们的工作\\任务何时触发@Beanpublic Trigger trigger()&#123; System.out.println(&quot;showTime触发器运行&quot;); // 定义Cron表达式，每分钟触发一次 CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule(&quot;0/10 * * * * ?&quot;); return TriggerBuilder.newTrigger() .forJob(jobDetail()) // 绑定JobDetail对象 .withIdentity(&quot;trigger&quot;) // 定义触发器名称 .withSchedule(cronScheduleBuilder) // 绑定Cron表达式 .build();&#125; } 步骤:3：定义Job 1234567public class QuartzJob implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) &#123; // 输出当前时间 System.out.println(LocalDateTime.now()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/categories/java/"}],"tags":[{"name":"定时器","slug":"定时器","permalink":"http://cloud-tour.github.io/tags/%E5%AE%9A%E6%97%B6%E5%99%A8/"}]},{"title":"new对象时的堆抢占问题","slug":"new对象时堆抢占问题","date":"2023-04-05T06:29:33.616Z","updated":"2023-04-06T09:12:56.054Z","comments":true,"path":"2023/04/05/new对象时堆抢占问题/","link":"","permalink":"http://cloud-tour.github.io/2023/04/05/new%E5%AF%B9%E8%B1%A1%E6%97%B6%E5%A0%86%E6%8A%A2%E5%8D%A0%E9%97%AE%E9%A2%98/","excerpt":"","text":"new对象时的堆抢占问题 问题引出-----当我们在new多个对象时，jvm在堆中给对象分配内存时，堆会不会发生抢占？ TLAB 首先，一个解决方案就是TLAB（Thread Local Allocation Buffer），即**线程本地分配缓存区** 什么是TLAB？它是干什么的？咋们先抛开这个问题，一切的开始得从new对象到指针碰撞开始讲起。 指针碰撞与空闲列表 java中我们要创建一个对象,用关键字new就可以了。而此时，jvm内部会对新建的对象分配内存。为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。而对于内存空间的分配，不同的垃圾回收器会有不同的分配方式。 指针碰撞(Serial、ParNew等带Compact过程的收集器) 假设JVM虚拟机上，堆内存都是规整的。堆内存被一个指针一分为二。指针的左边都被塞满了对象，指针的右变是未使用的区域。每一次有新的对象创建，指针就会向右移动一个对象size的距离。这就被称为指针碰撞。 那么问题来了。如果我们多线程执行new对象操作，一个线程正在给A对象分配内存，指针还没有来的及修改，其它为B对象分配内存的线程，而且还是引用这之前的指针指向。这样就出现毛病了。 如果想避免冲突的话,我们可以进行加锁,但是加锁会导致性能比较低,因此JVM里没有采用这种方式 空闲列表(CMS这种基于Mark-Sweep算法的收集器) 如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（Free List）。 TLAB解决 我们现在已经搞清楚，指针碰撞时会出现了哪些问题。而TLAB就是这个问题的解决方案之一。 TLAB的全称是**Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。** 设置方式 设置虚拟机参数**-XX:UseTLAB**，可开启虚拟机本地分配缓存区 通过选项**-XX:TLABWasteTargetPercent**，可设置TLAB空间所占用Eden空间的百分比大小（TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%）。 **-XX:+PrintTLAB**可以跟踪TLAB的使用情况。一般不建议手工修改TLAB相关参数，推荐使用虚拟机默认行为。 如果想要禁用自动调整TLAB的大小，可以使用**-XX:-ResizeTLAB禁用ResizeTLAB，并使用-XX:TLABSize**手工指定一个TLAB的大小。 解决问题原理 在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。 TLAB的本质其实是三个指针管理的区域：start，top 和 end，每个线程都会从Eden分配一块空间，例如说100KB，作为自己的TLAB，其中 start 和 end 是占位用的，标识出 eden 里被这个 TLAB 所管理的区域，卡住eden里的一块空间不让其它线程来这里分配。 TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 TLAB的问题 事务总不是完美的，TLAB也又自己的缺点。因为TLAB通常很小，所以放不下大对象。 TLAB空间大小是固定的，但是这时候来了一个大对象，我TLAB剩余的空间肯定就容不下它了。(比如100kb的TLAB，来了个110KB的对象) TLAB空间还剩一点点没有用到，但是又装不下稍微大一点的对象。(比如100kb的TLAB，装了80KB，又来了个30KB的对象) 这时虚拟机会有两种选择，第一，废弃当前TLAB，这样就会浪费20KB空间；第二，将这30KB的对象直接分配在堆上，保留当前的TLAB，这样可以希望将来有小于20KB的对象分配请求可以直接使用这块空间。 虚拟机内部解决 实际上虚拟机内部会维护一个叫作refill_waste(最大浪费空间)的值，当请求对象大于refill_waste时，会选择在堆中分配，若小于该值，且当前TLAB的剩余的空间小于最大浪费空间，则会废弃当前TLAB，新建TLAB来分配对象 这个阈值可以使用TLABRefillWasteFraction来调整，它表示TLAB中允许产生这种浪费的比例。默认值为64，即表示使用约为1/64的TLAB空间作为refill_waste。 默认情况下，TLAB和refill_waste都会在运行时不断调整的，使系统的运行状态达到最优。 当然，又回造成新的病垢 Eden空间够的时候，你再次申请TLAB没问题，我不够了，Heap的Eden区要开始GC， TLAB允许浪费空间，导致Eden区空间不连续，积少成多。以后还要人帮忙打理。 栈上分配 java中我们要创建一个对象,用关键字new就可以了。但是，在我们日常中，有很多生命周期很短的对象。比如： 1234public void dome()&#123; User user=new user(); user.sayhi();&#125; 这种对象的作用域都不会逃逸出方法外，也就是说该对象的生命周期会随着方法的调用开始而开始，方法的调用结束而结束。 ​ 在JVM中，堆是线程共享的，因此堆上的对象对于各个线程都是共享和可见的，只要持有对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收堆中不再使用的对象，但对于垃圾收集器来说，无论筛选可回收对象，还是回收和整理内存都需要耗费时间。 ​ 如果确定一个对象的作用域不会逃逸出方法之外，那可以将这个对象分配在栈上，这样，对象所占用的内存空间就可以随栈帧出栈而销毁。在一般应用中，不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，无须通过垃圾收集器回收，可以减小垃圾收集器的负载。 JVM允许将线程私有的对象打散分配在栈上，而不是分配在堆上。分配在栈上的好处是可以在函数调用结束后自行销毁，而不需要垃圾回收器的介入，从而提高系统性能。 栈上分配方式： 逃逸分析：逃逸分析的目的是判断对象的作用域是否有可能逃逸出函数体。 标量替换：允许将对象打散分配在栈上，比如若一个对象拥有两个字段，会将这两个字段视作局部变量进行分配。 开启方式： 只能在server模式下才能启用逃逸分析 参数**-XX:DoEscapeAnalysis**启用逃逸分析,Java SE 6u23版本之后，HotSpot中默认就开启了逃逸分析 参数**-XX:+EliminateAllocations**开启标量替换（默认打开） 可以通过选项**-XX:+PrintEscapeAnalysis**查看逃逸分析的筛选结果","categories":[{"name":"jvm","slug":"jvm","permalink":"http://cloud-tour.github.io/categories/jvm/"}],"tags":[{"name":"堆抢占","slug":"堆抢占","permalink":"http://cloud-tour.github.io/tags/%E5%A0%86%E6%8A%A2%E5%8D%A0/"}]},{"title":"JVM跨代引用问题的处理方式","slug":"JVM中跨代引用的处理方式","date":"2023-04-05T06:14:22.940Z","updated":"2023-04-19T17:17:23.513Z","comments":true,"path":"2023/04/05/JVM中跨代引用的处理方式/","link":"","permalink":"http://cloud-tour.github.io/2023/04/05/JVM%E4%B8%AD%E8%B7%A8%E4%BB%A3%E5%BC%95%E7%94%A8%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/","excerpt":"","text":"JVM跨代引用问题的处理方式 ------参考自《深入理解java虚拟机》 跨代引用 场景： 年轻代的对象持有着老年代对象的引用、老年代的对象持有着年轻代对象的引用 比如：（老年代中对象存在新生代对象的引用） 可以看到，老年代的对象HumongN被GCRoots所引用，此时HumongN-&gt;S就是跨代引用。S又引用着E，因此这三个对象都不是垃圾。在新生代中，由E找到S是非常快速简单的。然而由S找到HumongN就需要遍历整个老年代的对象，这个过程是相当耗时的。所以要避免每次 YGC 时扫描整个老年代，减少开销。 引出： 首先，产生跨代引用场景是发生YongGC的过程。此时新生代的对象会开始寻找根，看自己是否属于根可达对象，从而判断自己是否是垃圾。 那么就出现了问题，判断对象是否存活，不是应该是从GC Roots开始寻找，使用复杂的三色标记算法后，将判定不存活的对象删除掉么？ 但事实上，并不是所有老年代的对象都会引用着新生代的对象。那么相对频繁的YongGC，每次都从根节点遍历一次，效率就会被严重影响。 跨代引用带来的问题： minor gc（新生代垃圾回收）时需要扫描老年代，因为可能存在老年代对象引用年轻代对象（说明年轻代对象是可达的，不可回收）。 major gc（老年代垃圾回收）时需要扫描年轻代，因为可能存在年轻代对象引用老年代对象（说明老年代对象是可达的，不可回收）。 记忆集 ​ 为解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为**记忆集（Remembered Set)**的数据结构，用以避免把整个老年代加进GC Roots扫描范围。 ​ 事实上并不只是新生代、老年代之间才有跨代引用的问题，所有涉及部分区域收集（PartialGC）行为的垃圾收集器，典型的如G1、ZGC和Shenandoah收集器，都会面临相同的问题。记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。如果我们不考虑效率和成本的话，最简单的实现可以用非收集区域中所有含跨代引用的对象数组来实现这个数据结构。 注意记忆集的说辞：抽象。意思就是说记忆集是一种逻辑上的概念，并没有规定具体的实现，类似方法区。下文我们会说到卡表，可以把记忆集和卡表的关系理解为Map跟HashMap。 卡表 ​ 垃圾收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了，并不需要了解这些跨代指针的全部细节。那设计者在实现记忆集的时候，便可以选择更为粗犷的记录粒度来节省记忆集的存储和维护成本，下面列举了一些可供选择（当然也可以选择这个范围以外的）的记录精度： 字长精度：每个记录精确到一个机器字长(就是处理器的寻址位数，如常见的32位或64位，这个精度决定了机器访问物理内存地址的指针长度），该字包含跨代指针。 对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针。 卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。 ​ 其中，第三种“卡精度”所指的是用一种称为**“卡表”（Card Table)**的方式去实现记忆集，这也是目前最常用的一种记忆集实现形式，一些资料中甚至直接把它和记忆集混为一谈。前面定义中提到记忆集其实是一种“抽象”的数据结构，抽象的意思是只定义了记忆集的行为意图，并没有定义其行为的具体实现。 ​ 卡表就是记忆集的一种具体实现，它定义了记忆集的记录精度、与堆内存的映射关系等 在Hotspot虚拟机里面，卡表采用的是字节数组的形式。以下这行代码是HotSpot默认的卡表标记逻辑 ： 1CARD_TABLE [this address &gt;&gt; 9] = 0; ​ 字节数组CARD_TABLE的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作**“卡页”（Card Page）。一般来说，卡页大小都是以2的N次幂的字节数，通过上面代码可以看出HotSpot中使用的卡页是2的9次幂，即512字节**。那如果卡表标识内存区域的起始地址是0x0000的话，数组CARD_TABLE的第0、1、2号元素，分别对应了地址范围为0x0000～0x01FF、0x0200～0x03FF、0x0400～0x05FF的卡页内存块 ，如图所示： 卡表的标记规则： 一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏（Dirty），没有则标识为0。 在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入GC Roots中一并扫描。 卡表维护 ​ 我们已经解决了如何使用记忆集来缩减GC Roots扫描范围的问题，但还没有解决卡表元素如何维护的问题，例如它们何时变脏、谁来把它们变脏等。 解决： 先来解决何时变脏的问题，这个问题很简单，即其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻。 而解决如何变脏问题，在HotSpot 虚拟机里是通过**写屏障（Write Barrier)**技术维护卡表状态解决的。 注意：这里提到的 写屏障 和 volatile 的写屏障不是一回事。 写屏障 写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形（Around）通知。 在赋值前的部分的写屏障叫作写前屏障（Pre-Write Barrier），在赋值后的则叫作写后屏障（Post-Write Barrier）。 HotSpot虚拟机的许多收集器中都有使用到写屏障，但直至G1收集器出现之前，其他收集器都只用到了写后屏障。 应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令 ​ 一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生额外的开销，不过这个开销与Minor GC时扫描整个老年代的代价相比还是低得多的。 写屏障伪共享 ​ 卡表在高并发场景下还面临着 **“伪共享”（False Sharing）问题。伪共享是处理并发底层细节时一种经常需要考虑的问题，号称并发的隐形杀手，现代中央处理器的缓存系统中是以缓存行（Cache Line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量恰好共享同一个缓存行，就会彼此影响（写回、无效化或者同步）**而导致性能降低，这就是伪共享问题。 ​ 为了避免伪共享问题，一种简单的解决方案是不采用无条件的写屏障，而是先检查卡表标记，只有当该卡表元素未被标记过时才将其标记为变脏，即将卡表更新的逻辑变为以下代码所示： 相当于说就是多了一个if判断条件。 12if (CARD_TABLE [this address &gt;&gt; 9] != 0)CARD_TABLE [this address &gt;&gt; 9] = 0; 在JDK 7之后，HotSpot虚拟机增加了一个新的参数-XX：+UseCondCardMark（默认是关闭的），用来决定是否开启卡表更新的条件判断。开启会增加一次额外判断的开销，但能够避免伪共享问题，两者各有性能损耗，是否打开要根据应用实际运行情况来进行测试权衡。","categories":[{"name":"jvm","slug":"jvm","permalink":"http://cloud-tour.github.io/categories/jvm/"}],"tags":[{"name":"跨代引用","slug":"跨代引用","permalink":"http://cloud-tour.github.io/tags/%E8%B7%A8%E4%BB%A3%E5%BC%95%E7%94%A8/"}]},{"title":"AQS原理流程解析","slug":"AQS原理流程解析","date":"2023-04-02T14:30:07.396Z","updated":"2023-04-04T04:42:13.770Z","comments":true,"path":"2023/04/02/AQS原理流程解析/","link":"","permalink":"http://cloud-tour.github.io/2023/04/02/AQS%E5%8E%9F%E7%90%86%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/","excerpt":"","text":"AQS 概述 全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架 AQS定义了一套多线程访问共享资源的同步模板，解决了实现同步器时涉及的大量细节问题，能够极大地减少实现工作 AQS的组成结构 三部分组成：volatile int state同步状态、Node组成的CLH队列、ConditionObject条件变量（包含Node组成的条件单向队列）。 特点： 用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁 getState - 获取 state 状态 setState - 设置 state 状态 compareAndSetState - cas 机制设置 state 状态 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源 ReentrantLock的state用来表示是否有锁资源 ReentrantReadWriteLock的state高16位代表读锁状态，低16位代表写锁状态 Semaphore的state用来表示可用信号的个数 CountDownLatch的state用来表示计数器的值 提供了基于 FIFO （先进先出）的等待队列，类似于 Monitor 的 EntryList 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet 子类主要实现这样一些方法（默认抛出 UnsupportedOperationException） tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively 获取锁的姿势： 1234// 如果获取锁失败if (!tryAcquire(arg)) &#123; // 入队, 可以选择阻塞当前线程 park unpark&#125; 释放锁的姿势 1234// 如果释放锁成功if (tryRelease(arg)) &#123; // 让阻塞线程恢复运行&#125; 例子 实现不可重入锁 自定义同步器 1234567891011121314151617181920212223242526272829303132333435final class MySync extends AbstractQueuedSynchronizer &#123; @Override protected boolean tryAcquire(int acquires) &#123; if (acquires == 1)&#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; &#125; return false; &#125; @Override protected boolean tryRelease(int acquires) &#123; if(acquires == 1) &#123; if(getState() == 0) &#123; throw new IllegalMonitorStateException(); &#125; setExclusiveOwnerThread(null); setState(0); return true; &#125; return false; &#125; protected Condition newCondition() &#123; return new ConditionObject(); &#125; @Override protected boolean isHeldExclusively() &#123; return getState() == 1; &#125;&#125; 自定义锁 有了自定义同步器，很容易复用 AQS ，实现一个功能完备的自定义锁 12345678910111213141516171819202122232425262728293031323334353637383940class MyLock implements Lock &#123; static MySync sync = new MySync(); @Override // 尝试，不成功，进入等待队列 public void lock() &#123; sync.acquire(1); &#125; @Override // 尝试，不成功，进入等待队列，可打断 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override // 尝试一次，不成功返回，不进入队列 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override // 尝试，不成功，进入等待队列，有时限 public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override // 释放锁 public void unlock() &#123; sync.release(1); &#125; @Override // 生成条件变量 public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; CLH队列 CLH是AQS内部维护的FIFO（先进先出）双端双向队列（方便尾部节点插入），基于链表数据结构，当一个线程竞争资源失败，就会将等待资源的线程封装成一个Node节点，通过CAS原子操作插入队列尾部，最终不同的Node节点连接组成了一个CLH队列，所以说AQS通过CLH队列管理竞争资源的线程，个人总结CLH队列具有如下几个优点： 先进先出保证了公平性 非阻塞的队列，通过自旋锁和CAS保证节点插入和移除的原子性，实现无锁快速插入 采用了自旋锁思想，所以CLH也是一种基于链表的可扩展、高性能、公平的自旋锁 流程 线程获取资源失败，封装成Node节点从CLH队列尾部入队并阻塞线程，某线程释放资源时会把CLH队列首部Node节点关联的线程唤醒（此处的首部是指第二个节点，后面会细说），再次获取资源。， 入队 获取资源失败的线程需要封装成Node节点，接着尾部入队，在AQS中提供addWaiter函数完成Node节点的创建与入队。 添加节点的时候，如果从CLH队列已经存在，通过CAS快速将当前节点添加到队列尾部，如果添加失败或队列不存在，则指向enq函数自旋入队。 通过自旋CAS尝试往队列尾部插入节点，直到成功，自旋过程如果发现CLH队列不存在时会初始化CLH队列，入队过程流程如下图： 第一次循环 刚开始C L H队列不存在，head与tail都指向null 要初始化C L H队列，会创建一个哨兵节点，head与tail都指向哨兵节点 第二次循环 当前线程节点的前驱节点指向尾部节点（哨兵节点） 设置当前线程节点为尾部，tail指向当前线程节点 前尾部节点的后驱节点指向当前线程节点（当前尾部节点） 最后结合addWaiter与enq函数的入队流程图如下 出队 CLH队列中的节点都是获取资源失败的线程节点，当持有资源的线程释放资源时，会将head.next指向的线程节点唤醒（CLH队列的第二个节点），如果唤醒的线程节点获取资源成功，线程节点清空信息设置为头部节点（新哨兵节点），原头部节点出队（原哨兵节点）acquireQueued函数中的部分代码 假设获取资源成功，更换头部节点，并把头部节点的信息清除变成哨兵节点，注意这个过程是不需要使用CAS来保证，因为只有一个线程能够成功获取到资源。 条件变量 Object的wait、notify函数是配合Synchronized锁实现线程间同步协作的功能，A Q S的ConditionObject条件变量也提供这样的功能，通过ConditionObject的await和signal两类函数完成。不同于Synchronized锁，一个A Q S可以对应多个条件变量，而Synchronized只有一个 如上图所示，ConditionObject内部维护着一个单向条件队列，不同于C H L队列，条件队列只入队执行await的线程节点，并且加入条件队列的节点，不能在C H L队列， 条件队列出队的节点，会入队到C H L队列。 当某个线程执行了ConditionObject的await函数，阻塞当前线程，线程会被封装成Node节点添加到条件队列的末端，其他线程执行ConditionObject的signal函数，会将条件队列头部线程节点转移到C H L队列参与竞争资源，具体流程如下图 共享方式 AQS定义两种资源共享方式。无论是独占锁还是共享锁，本质上都是对AQS内部的一个变量state的获取。state是一个原子的int变量，用来表示锁状态、资源数等。 ① 独占锁(Exclusive)模式：只能被一个线程获取到(Reentrantlock)。 ② 共享锁(Share)模式：可以被多个线程同时获取(Semaphore/CountDownLatch/ReadWriteLock)。 state机制 提供volatile变量state，用于同步线程之间的共享状态。通过 CAS 和 volatile 保证其原子性和可见性。核心要点： state 用 volatile 修饰，保证多线程中的可见性 getState() 和 setState() 方法采用final修饰，限制AQS的子类重写它们两 compareAndSetState() 方法采用乐观锁思想的CAS算法，也是采用final修饰的，不允许子类重写 state应用案例： 案例 描述 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease） ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理 基于AQS实现的类 Semaphore 用来限制能同时访问共享资源的线程上限。 Semaphore是一个计数信号量，它的本质是一个&quot;共享锁&quot;。信号量维护了一个信号量许可集。线程可以通过调用acquire()来获取信号量的许可；当信号量中有可用的许可时，线程能获取该许可；否则线程必须等待，直到有可用的许可为止。 线程可以通过release()来释放它所持有的信号量许可。 流程 Semaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后 停车场显示空余车位减一 刚开始，permits（state）为 3，这时 5 个线程来获取资源 假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列 park 阻塞 这时 Thread-4 释放了 permits，状态如下 接下来 Thread-0 竞争成功，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接 下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态 CountDownLatch 用来进行线程同步协作，等待所有线程完成倒计时。 其中构造参数用来初始化等待计数值，await() 用来等待计数归零，countDown() 用来让计数减一 CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 原理 CountDownLatch也是基于AQS实现的，它的实现机制很简单 当我们在构建CountDownLatch对象时，传入的值其实就会赋值给 AQS 的关键变量state 执行countDown方法时，其实就是利用CAS 将state 减一 执行await方法时，其实就是判断state是否为0，不为0则加入到队列中，将该线程阻塞掉（除了头结点） 因为头节点会一直自旋等待state为0，当state为0时，头节点把剩余的在队列中阻塞的节点也一并唤醒 CountDownLatch和CyclicBarrier的区别 CountDownLatch允许一个或多个线程一直等待，直到这些线程完成它们的操作，而CyclicBarrier不一样，它往往是当线程到达某状态后，暂停下来等待其他线程，等到所有线程均到达以后，才继续执行 CountDownLatch调用await()通常是主线程/调用线程，而CyclicBarrier调用await()是在任务线程调用的。所以，CyclicBarrier中的阻塞的是任务的线程，而主线程是不受影响的。 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier CyclicBarrier 循环栅栏，用来进行线程协作，等待线程满足某个计数。构造时设置『计数个数』，每个线程执 行到某个需要“同步”的时刻调用 await() 方法进行等待，当等待的线程数满足『计数个数』时，继续执行 CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 原理 从源码不难发现的是，它没有像CountDownLatch和ReentrantLock使用AQS的state变量，而CyclicBarrier是直接借助ReentrantLock加上Condition 等待唤醒的功能进而实现的 在构建CyclicBarrier时，传入的值会赋值给CyclicBarrier内部维护count变量，也会赋值给parties变量（这是可以复用的关键） 每次调用await时，会将count -1 ，操作count值是直接使用ReentrantLock来保证线程安全性 如果count不为0，则添加线程到condition队列中 如果count等于0时，则把节点从condition队列添加至AQS的队列中进行全部唤醒，并且将parties的值重新赋值为count的值（实现复用）","categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"http://cloud-tour.github.io/tags/AQS/"}]},{"title":"ReentrantLock底层实现解析","slug":"ReentrantLock底层实现解析","date":"2023-04-02T12:08:51.583Z","updated":"2023-04-05T04:43:21.204Z","comments":true,"path":"2023/04/02/ReentrantLock底层实现解析/","link":"","permalink":"http://cloud-tour.github.io/2023/04/02/ReentrantLock%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/","excerpt":"","text":"ReentrantLock ReentrantLock是可重入的互斥锁，虽然具有与synchronized相同功能，但是会比synchronized更加灵活（具有更多的方法）。 ReentrantLock底层基于AbstractQueuedSynchronizer实现。 AbstractQueuedSynchronizer（AQS）抽象类定义了一套多线程访问共享资源的同步模板，解决了实现同步器时涉及的大量细节问题，能够极大地减少实现工作，用大白话来说，AbstractQueuedSynchronizer为加锁和解锁过程提供了统一的模板函数，只有少量细节由子类自己决定。关于AQS详细，可看本博客另一篇介绍AQS的文章。 相对于 synchronized 它具备如下特点 可中断 可以设置超时时间 可以设置为公平锁 支持多个条件变量 与 synchronized 一样，都支持可重入 基本用法： 12345678// 获取锁reentrantLock.lock();try &#123; // 临界区&#125; finally &#123; // 释放锁 reentrantLock.unlock();&#125; 内部总体流程图： ReentrantLock结构组成 从类结构可看出，ReentrantLock实现了lock接口。Lock接口是Java中对锁操作行为的统一规范 Lock接口定义的函数不多，接下来ReentrantLock要去实现这些函数，遵循着解耦可扩展设计，ReentrantLock内部定义了专门的组件Sync， Sync继承AbstractQueuedSynchronizer提供释放资源的实现，NonfairSync和FairSync是基于Sync扩展的子类，即ReentrantLock的非公平模式与公平模式，它们作为Lock接口功能的基本实现。 Sync sync是ReentrantLock的一个内部类，它继承了AbstractQueuedSynchronizer，是ReentrantLock的核心，后面的NonfairSync与FairSync都是基于Sync扩展出来的子类。 核心代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//获取锁，子类实现abstract void lock();//非公平--获取资源final boolean nonfairTryAcquire(int acquires) &#123; //得到当前线程 final Thread current = Thread.currentThread(); //拿到state状态 int c = getState(); if (c == 0) &#123;//state为0表示资源可获取 //进行cas设置state if (compareAndSetState(0, acquires)) &#123; //若设置成功，就设置当前持有锁的线程 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//若state不为0但当前线程为持有锁的线程，则state+1 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125;//释放资源 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //如果当前线程不是持有锁线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //若最终state-1后为0就表示释放资源成功 if (c == 0) &#123; //返回状态改为成功 free = true; //清空持有锁线程 setExclusiveOwnerThread(null); &#125; //如果state-1后，state还是&gt;0,代表当前线程有锁重入，需要做相应的释放次数才能释放锁，设置state值 setState(c); return free; &#125; Sync逻辑都比较简单，实现了AQS类的释放资源（tryRelease），然后抽象了一个获取锁的函数让子类自行实现（lock），再加一个偏心的函数nonfairTryAcquire tryRelease流程图： nonfairTryAcquire流程图： NonfairSync 在ReentrantLock中支持两种获取锁的策略，分别是非公平策略与公平策略，NonfairSync就是非公平策略。 公平和非公平如何体现？ AQS为加锁和解锁过程提供了统一的模板函数，加锁与解锁的模板流程是，获取锁失败的线程，会进入CLH队列阻塞，其他线程解锁会唤醒CLH队列线程 线程释放锁时，会唤醒CLH队列阻塞的线程，重新竞争锁，要注意，此时可能还有非CLH队列的线程参与竞争，所以非公平就体现在这里，非CLH队列线程与CLH队列线程竞争，各凭本事，不会因为你是CLH队列的线程，就把锁让给你。 接下来看NonfairSync的内部实现： 123456789101112131415static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; //获取锁 final void lock() &#123; if (compareAndSetState(0, 1))//cas替换成功，表示获取锁成功 setExclusiveOwnerThread(Thread.currentThread()); else //cas替换失败，则进入执行AQS获取锁模板流程 acquire(1); &#125; //获取资源--使用父类提供的方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; NonfairSync继承Sync实现了lock函数，lock函数也非常简单，CAS设置状态值state为1代表获取锁成功，否则执行AQS的acquire函数（获取锁模板），另外NonfairSync还实现了AQS留给子类实现的tryAcquire函数（获取资源），但是这个子类中直接使用了父类Sync提供的nonfairTryAcquire函数来实现tryAcquire，最后子类实现的tryAcquire函数在AQS的acquire函数中被使用。 对于AQS获取锁模板流程，实现代码： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; //获取失败，后面就进入CLH入队流程。本文不关注 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 基于上述内容，可做出以下关系图方便理解： 解析：首先AQS的acquire函数是获取锁的流程模板，模板流程会先执行tryAcquire函数获取资源，tryAcquire函数要子类实现，NonfairSync作为子类，实现了tryAcquire函数，具体实现是调用了Sync的nonfairTryAcquire函数。 FairSync 与NonfairSync相反，FairSync就是非公平策略。 所谓公平策略就是，严格按照CLH队列顺序获取锁，线程释放锁时，会唤醒CLH队列阻塞的线程，重新竞争锁，要注意，此时可能还有非CLH队列的线程参与竞争，为了保证公平，一定会让CLH队列线程竞争成功，如果非CLH队列线程一直占用时间片，那就一直失败（构建成节点插入到CLH队尾，由ASQ模板流程执行），直到时间片轮到CLH队列线程为止，所以公平策略的性能会更差。 FairSync类定义： 1234567891011121314151617181920212223242526272829303132333435static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; //进入AQS获取锁模板流程 acquire(1); &#125; //获取资源 protected final boolean tryAcquire(int acquires) &#123; //获取当前线程 final Thread current = Thread.currentThread(); //取出state int c = getState(); if (c == 0) &#123;//state为0表示资源可获取 //1.!hasQueuedPredecessors--判断当前线程是否为CHL队列被唤醒的线程，若是则进入&amp;&amp;后函数 //2.cas设置state if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //cas成功，设置当前线程为持有锁线程 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//若state不为0但当前线程为持有锁的线程，表示重入则state+1 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; 不难发现FairSync流程与NonfairSync基本一致，唯一的区别就是在CAS执行前，多了一步hasQueuedPredecessors函数，这一步就是判断当前线程是不是CLH队列被唤醒的线程，如果是就执行CAS，否则获取资源失败 流程图： ReentrantLock中lock的实现 源码（只贴出主要部分）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class ReentrantLock implements Lock, java.io.Serializable &#123; //同步器 private final Sync sync; //默认使用非公平锁策略 public ReentrantLock() &#123; sync = new NonfairSync(); &#125; //true-公平锁，false-非公平锁 public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; //获取锁--阻塞 public void lock() &#123; sync.lock(); &#125; //支持中断地获取锁操作--阻塞 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; //获取资源并返回状态--非阻塞 public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; //支持超时获取资源并返回状态--非阻塞 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; //释放锁 public void unlock() &#123; sync.release(1); &#125; //创建条件变量 public Condition newCondition() &#123; return sync.newCondition(); &#125; &#125; 可以看出，ReentrantLock对Lock的实现都是基于Sync来做的， 条件变量 synchronized 中也有条件变量，就是那个 waitSet （类比为休息室），当条件不满足时进入 waitSet 等待 ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比 synchronized 是那些不满足条件的线程都在一间休息室等消息 而 ReentrantLock 支持多间休息室，有专门等物品的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒 使用要点： await 前需要获得锁 await 执行后，会释放锁，进入 conditionObject 等待 await 的线程被唤醒（或打断、或超时）取重新竞争 lock 锁 竞争 lock 锁成功后，从 await 后继续执行 非公平锁实现原理流程图 上面从代码层面解析了公平和非公平的实现原理，那么具体的同步器流程是怎么样的呢？ 先从构造器开始看，默认为非公平锁实现 123public ReentrantLock() &#123; sync = new NonfairSync();&#125; NonfairSync 继承自 AQS 没有竞争时 第一个竞争出现时 Thread-1 执行了 CAS 尝试将 state 由 0 改为 1，结果失败 进入 tryAcquire 逻辑，这时 state 已经是1，结果仍然失败 接下来进入 addWaiter 逻辑，构造 Node 队列 图中黄色三角表示该 Node 的 waitStatus 状态，其中 0 为默认正常状态 Node 的创建是懒惰的 其中第一个 Node 称为 Dummy（哑元）或哨兵，用来占位，并不关联线程 当前线程进入 acquireQueued 逻辑 acquireQueued 会在一个死循环中不断尝试获得锁，失败后进入 park 阻塞 如果自己是紧邻着 head（排第二位），那么再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 进入 shouldParkAfterFailedAcquire 逻辑，将前驱 node，即 head 的 waitStatus 改为 -1，这次返回 false shouldParkAfterFailedAcquire 执行完毕回到 acquireQueued ，再次 tryAcquire 尝试获取锁，当然这时 state 仍为 1，失败 当再次进入 shouldParkAfterFailedAcquire 时，这时因为其前驱 node 的 waitStatus 已经是 -1，这次返回 true 进入 parkAndCheckInterrupt， Thread-1 park（灰色表示） 再次有多个线程经历上述过程竞争失败，变成这个样子 Thread-0 释放锁，进入 tryRelease 流程，如果成功 设置 exclusiveOwnerThread 为 null state = 0 当前队列不为 null，并且 head 的 waitStatus = -1，进入 unparkSuccessor 流程 找到队列中离 head 最近的一个 Node（没取消的），unpark 恢复其运行，本例中即为 Thread-1 回到 Thread-1 的 acquireQueued 流程 如果加锁成功（没有竞争），会设置 exclusiveOwnerThread 为 Thread-1，state = 1 head 指向刚刚 Thread-1 所在的 Node，该 Node 清空 Thread 原本的 head 因为从链表断开，而可被垃圾回收 如果这时候有其它线程来竞争（非公平的体现），例如这时有 Thread-4 来了 如果不巧又被 Thread-4 占了先 Thread-4 被设置为 exclusiveOwnerThread，state = 1 Thread-1 再次进入 acquireQueued 流程，获取锁失败，重新进入 park 阻塞 条件变量实现原理 每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject await 流程 开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程 创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部 接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁 unpark AQS 队列中的下一个节点，竞争锁，假设没有其他竞争线程，那么 Thread-1 竞争成功 park 阻塞 Thread-0 signal 流程 假设 Thread-1 要来唤醒 Thread-0 进入 ConditionObject 的 doSignal 流程，取得等待队列中第一个 Node，即 Thread-0 所在 Node 执行 transferForSignal 流程，将该 Node 加入 AQS 队列尾部，将 Thread-0 的 waitStatus 改为 0，Thread-3 的 waitStatus 改为 -1 Thread-1 释放锁，进入 unlock 流程","categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"}],"tags":[{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"http://cloud-tour.github.io/tags/ReentrantLock/"},{"name":"Lock","slug":"Lock","permalink":"http://cloud-tour.github.io/tags/Lock/"}]},{"title":"java线程池详解","slug":"java线程池详解","date":"2023-04-02T11:55:50.087Z","updated":"2023-04-04T04:42:52.373Z","comments":true,"path":"2023/04/02/java线程池详解/","link":"","permalink":"http://cloud-tour.github.io/2023/04/02/java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"线程池 线程池（thread pool）：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，对线程统一管理。 线程池就是存放线程的池子，池子里存放了很多可以复用的线程。 创建线程和销毁线程的花销是比较大的（手动new Thread 类），创建和消耗线程的时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程是比较消耗资源的。（我们可以把创建和销毁的线程的过程去掉）。 线程池状态 ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量 从数字上比较，TERMINATED &gt; TIDYING &gt; STOP &gt; SHUTDOWN &gt; RUNNING 这些信息存储在一个原子变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作 进行赋值 running：初始化后的状态，表示线程池可以处理任务。 shutdown：调用线程池的shutdown方法会使线程进入shutdown状态，从而调用execute的时候会抛出异常。但如果阻塞队列中还有任务，则会先将阻塞队列中的认为执行完，才会后收所有线程。 stop：调用线程池的shutdownnow方法会使线程进入stop状态，既不能接受新的任务，也不能把阻塞队列中的任务执行完。 tidying：在执行玩shutdownnow方法的时候，关闭完所有线程的时候，就会调用tryTerminate（）方法 terminated：线程池处于TIDYING状态后，会执行terminated（）方法，执行完后就i进入terminated状态，在ThreadPoolExecutor中的terminated（）是一个空方法，可以自定义线程池重写这个方法，实现自定义的业务逻辑。 工作流程 提交任务 当工作线程数小于核心线程数时，直接创建新的核心工作线程 当工作线程数不小于核心线程数时，就需要尝试将任务添加到阻塞队列中去 如果能够加入成功，说明队列还没有满，那么需要做以下的二次验证来保证添加进去的任务能够成功被执行 验证当前线程池的运行状态，如果是非RUNNING状态，则需要将任务从阻塞队列中移除，然后拒绝该任务 验证当前线程池中的工作线程的个数，如果为0，则需要主动添加一个空工作线程来执行刚刚添加到阻塞队列中的任务 如果加入失败，则说明队列已经满了，那么这时就需要创建新的“临时”工作线程来执行任务 如果创建成功，则直接执行该任务 如果创建失败，则说明工作线程数已经等于最大线程数了，则只能拒绝该任务了 构造方法 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize 核心线程数目 (最多保留的线程数) CPU密集型：corePoolSize = CPU核数 + 1 IO密集型：corePoolSize = CPU核数 * 2 maximumPoolSize 最大线程数目 keepAliveTime 生存时间 - 针对救急线程 unit 时间单位 - 针对救急线程 workQueue 阻塞队列 threadFactory 线程工厂 - 可以为线程创建时起个好名字 handler 拒绝策略（可通过实现RejectedExecutionHandler 接口自定义拒绝策略） 工作队列 1、无界队列 队列大小无限制，常用的为无界的LinkedBlockingQueue，使用该队列作为阻塞队列时要尤其当心，当任务耗时较长时可能会导致大量新任务在队列中堆积最终导致OOM。阅读代码发现，Executors.newFixedThreadPool 采用就是 LinkedBlockingQueue，而博主踩到的就是这个坑，当QPS很高，发送数据很大，大量的任务被添加到这个无界LinkedBlockingQueue 中，导致cpu和内存飙升服务器挂掉。 当然这种队列，maximumPoolSize 的值也就无效了。当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 2、有界队列 当使用有限的 maximumPoolSizes 时，有界队列有助于防止资源耗尽，但是可能较难调整和控制。常用的有两类，一类是遵循FIFO原则的队列如ArrayBlockingQueue，另一类是优先级队列如PriorityBlockingQueue。PriorityBlockingQueue中的优先级由任务的Comparator决定。 使用有界队列时队列大小需和线程池大小互相配合，线程池较小有界队列较大时可减少内存消耗，降低cpu使用率和上下文切换，但是可能会限制系统吞吐量。 3、同步移交队列 如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列。SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制。要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列。 newFixedThreadPool 123456public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 特点 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间 阻塞队列是无界的，可以放任意数量的任务 评价 适用于任务量已知，相对耗时的任务 newCachedThreadPool 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 特点 核心线程数是 0， 最大线程数是 Integer.MAX_VALUE，救急线程的空闲生存时间是 60s，意味着 全部都是救急线程（60s 后可以回收） 救急线程可以无限创建 队列采用了 SynchronousQueue 实现特点是，它没有容量，没有线程来取是放不进去的（一手交钱、一手交 货） 评价 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1分钟后释放线 程。 适合任务数比较密集，但每个任务执行时间较短的情况 newSingleThreadExecutor 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 使用场景： 希望多个任务排队执行。线程数固定为 1，任务数多于 1 时，会放入无界队列排队。任务执行完毕，这唯一的线程 也不会被释放。 区别： 自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一 个线程，保证池的正常工作 Executors.newSingleThreadExecutor() 线程个数始终为1，不能修改 FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因 此不能调用 ThreadPoolExecutor 中特有的方法 Executors.newFixedThreadPool(1) 初始时为1，以后还可以修改 对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改 任务提交 123456789101112131415161718192021222324// 执行任务void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 关闭线程池 123456789101112131415161718192021222324/*线程池状态变为 SHUTDOWN - 不会接收新任务 - 但已提交任务会执行完 - 此方法不会阻塞调用线程的执行*/void shutdown();/*线程池状态变为 STOP - 不会接收新任务 - 会将队列中的任务返回 - 并用 interrupt 的方式中断正在执行的任务*/List&lt;Runnable&gt; shutdownNow();// 不在 RUNNING 状态的线程池，此方法就返回 trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，可以利用此方法等待 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 任务调度线程池 使用 ScheduledExecutorService 123456789ScheduledExecutorService executor = Executors.newScheduledThreadPool(2);// 添加两个任务，希望它们都在 1s 后执行executor.schedule(() -&gt; &#123; System.out.println(&quot;任务1，执行时间：&quot; + new Date()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125;&#125;, 1000, TimeUnit.MILLISECONDS);executor.schedule(() -&gt; &#123; System.out.println(&quot;任务2，执行时间：&quot; + new Date());&#125;, 1000, TimeUnit.MILLISECONDS); scheduleAtFixedRate 循环执行例子 12345ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; &#123; log.debug(&quot;running...&quot;);&#125;, 1, 1, TimeUnit.SECONDS); 输出： scheduleAtFixedRate 例子（任务执行时间超过了间隔时间）： 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleAtFixedRate(() -&gt; &#123; log.debug(&quot;running...&quot;); sleep(2);&#125;, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，接下来，由于任务执行时间 &gt; 间隔时间，间隔被『撑』到了 2s scheduleWithFixedDelay 例子： 123456ScheduledExecutorService pool = Executors.newScheduledThreadPool(1);log.debug(&quot;start...&quot;);pool.scheduleWithFixedDelay(()-&gt; &#123; log.debug(&quot;running...&quot;); sleep(2);&#125;, 1, 1, TimeUnit.SECONDS); 输出分析：一开始，延时 1s，scheduleWithFixedDelay 的间隔是 上一个任务结束 &lt;-&gt; 延时 &lt;-&gt; 下一个任务开始 所 以间隔都是 3s 评价 整个线程池表现为：线程数固定，任务数多于线程数时，会放入无界队列排队。任务执行完毕，这些线 程也不会被释放。用来执行延迟或反复执行的任务 Fork/Join Fork/Join 是 JDK 1.7 加入的新的线程池实现，它体现的是一种分治思想，适用于能够进行任务拆分的 cpu 密集型 运算 所谓的任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列、都可以用分治思想进行求解 Fork/Join 在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升了运算效率 Fork/Join 默认会创建与 cpu 核心数大小相同的线程池 使用： 提交给 Fork/Join 线程池的任务需要继承 RecursiveTask（有返回值）或 RecursiveAction（没有返回值），例如下 面定义了一个对 1~n 之间的整数求和的任务 123456789101112131415161718192021222324252627282930@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask1 extends RecursiveTask&lt;Integer&gt; &#123; int n; public AddTask1(int n) &#123; this.n = n; &#125; @Override public String toString() &#123; return &quot;&#123;&quot; + n + &#x27;&#125;&#x27;; &#125; @Override protected Integer compute() &#123; // 如果 n 已经为 1，可以求得结果了 if (n == 1) &#123; log.debug(&quot;join() &#123;&#125;&quot;, n); return n; &#125; // 将任务进行拆分(fork) AddTask1 t1 = new AddTask1(n - 1); t1.fork(); log.debug(&quot;fork() &#123;&#125; + &#123;&#125;&quot;, n, t1); // 合并(join)结果 int result = n + t1.join(); log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, n, t1, result); return result; &#125;&#125; 然后提交给 ForkJoinPool 来执行 12345public static void main(String[] args) &#123; ForkJoinPool pool = new ForkJoinPool(4); System.out.println(pool.invoke(new AddTask1(5)));&#125; 结果：","categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://cloud-tour.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}]},{"title":"Synchronized原理解析","slug":"synchronized原理解析","date":"2023-03-30T14:25:53.826Z","updated":"2023-04-05T04:43:53.528Z","comments":true,"path":"2023/03/30/synchronized原理解析/","link":"","permalink":"http://cloud-tour.github.io/2023/03/30/synchronized%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/","excerpt":"","text":"Synchronized原理解析 原理概述 ​ 在java中，对于会出现资源抢夺的代码段，通常会用Synchronized或lock锁来解决多线程问题。而对于Synchronized而言，他是java中的一个关键字。来自官方的解释：Synchronized方法支持一种简单的策略，用于防止线程干扰和内存一致性错误。 ​ 所以Synchronized能保证同一时刻有且只有一条线程在操作共享数据，其他线程必须等待该线程处理完数据后再对共享数据进行操作。Synchronized是最基本的互斥手段，保证同一时刻最多只有1个线程执行被Synchronized修饰的方法 / 代码，其他线程 必须等待当前线程执行完该方法 / 代码块后才能执行该方法 / 代码块。 java对象头 ​ 对于Synchronized的理解，首先要对对象头有所理解。在java中，每个对象都会有对象头，而对象头中，存储着对象的一些信息。其中就包括锁信息。 普通对象对象头： 数组对象对象头： 而在对象头中，Mark Word就存储着该对象相应的锁信息 64 位虚拟机 Mark Word结构： Monitor ​ 每个 Java 对象都可以关联一个 Monitor 对象，Monitor 被翻译为监视器或管程。如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针。 Monitor 对象结构： Owner：Monitor的拥有者，即指向正在使用锁的线程 EntryList：阻塞列表，没有竞争到锁的线程会进入list进行阻塞等待 WaitSet：等待池，调用wait方法的线程会进入等待池中进行等待 刚开始 Monitor 中 Owner 为 null 当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor中只能有一 个 Owner 在 Thread-2 上锁的过程中，如果 Thread-3，Thread-4，Thread-5 也来执行 synchronized(obj)，就会进入 EntryList BLOCKED Thread-2 执行完同步代码块的内容，然后唤醒 EntryList 中等待的线程来竞争锁，竞争的时是非公平的 图中 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但条件不满足进入 WAITING 状态的线程 注意： synchronized 必须是进入同一个对象的 monitor 才有上述的效果 不加 synchronized 的对象不会关联监视器，不遵从以上规则 wait、notify原理： Owner 线程发现条件不满足，调用 wait 方法，即可进入 WaitSet 变为 WAITING 状态 BLOCKED 和 WAITING 的线程都处于阻塞状态，不占用 CPU 时间片 BLOCKED 线程会在 Owner 线程释放锁时唤醒 WAITING 线程会在 Owner 线程调用 notify 或 notifyAll 时唤醒，但唤醒后并不意味者立刻获得锁，仍需进入 EntryList 重新竞争 偏向锁 ​ 轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作，这其实是一个可以优化的点。 ​ Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头，之后发现 这个线程 ID 是自己的就表示没有竞争，不用重新 CAS。以后只要不发生竞争，这个对象就归该线程所有 偏向状态 对象头格式 一个对象创建时： 如果开启了偏向锁（默认开启），那么对象创建后，markword 值为 0x05 即最后 3 位为 101，这时它的 thread、epoch、age 都为 0 偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加 VM 参数 - XX:BiasedLockingStartupDelay=0 来禁用延迟 如果没有开启偏向锁，那么对象创建后，markword 值为 0x01 即最后 3 位为 001，这时它的 hashcode、 age 都为 0，第一次用到 hashcode 时才会赋值 轻量级锁 ​ 轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以 使用轻量级锁来优化。 ​ 轻量级锁对使用者是透明的，即语法仍然是 synchronized ​ 假设有两个方法同步块，利用同一个对象加锁 123456789101112static final Object obj = new Object();public static void method1() &#123; synchronized( obj ) &#123; // 同步块 A method2(); &#125;&#125;public static void method2() &#123; synchronized( obj ) &#123; // 同步块 B &#125;&#125; 创建锁记录（Lock Record）对象，每个线程都的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的 Mark Word 让锁记录中 Object reference 指向锁对象，并尝试用 cas 替换 Object 的 Mark Word，将 Mark Word 的值存 入锁记录 如果 cas 替换成功，对象头中存储了 锁记录地址和状态 00 ，表示由该线程给对象加锁，这时图示如下 如果 cas 失败，有两种情况 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数 当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重 入计数减一 当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程 锁膨胀 ​ 如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁 这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 即为 Object 对象申请 Monitor 锁，让 Object 指向重量级锁地址 然后自己进入 Monitor 的 EntryList BLOCKED 当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程 自旋优化 ​ 线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。 ​ 所谓自旋锁，就是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。所以重量级锁竞争的时候，可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以避免阻塞。 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会 高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 Java 7 之后不能控制是否开启自旋功能 锁消除和锁粗化 锁消除： ​ 消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁。通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如StringBuffer的append是一个同步方法，但我们将StringBuffer作为一个局部变量使用，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 锁粗化： ​ 在使用同步锁的时候，需要让同步块的作用范围尽可能小——仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 ​ 在大多数的情况下，上述观点是正确的。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗化的概念。 ​ 锁粗化概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁 锁升级过程 每种锁是只能升级，不能降级，即由偏向锁-&gt;轻量级锁-&gt;重量级锁，而这个过程就是开销逐渐加大的过程。 如果是单线程使用，那偏向锁毫无疑问代价最小，并且它就能解决问题，连CAS都不用做，仅仅在内存中比较下对象头就可以了； 如果出现了其他线程竞争，则偏向锁就会升级为轻量级锁； 如果其他线程通过一定次数的CAS尝试没有成功，则进入重量级锁； 字节码层面解析 同步代码块 ​ Synchronized同步代码块时，如果查看编译后的字节码，会发现，被Synchronized修饰过的程序块，在编译前后被编译器生成了monitorenter和monitorexit两个字节码指令，其中，monitorexit指令出现了两次。monitorenter指向同步代码块的开始位置，monitorexit指明同步代码块的结束位置。 ​ 先看monitorenter指令。每个对象都是一个监视器锁（monitor）（不加 synchronized 的对象不会关联监视器），在虛拟机执行到monitorenter指令时，首先要尝试获取对象的锁，获取monitor的所有权： 如果monitor的Owner为null，表示这个对象没有被锁定，则该线程进入monitor，然后将monitor的Owner设置为该线程，该线程即为monitor的所有者； 如果线程已经占有该monitor，说明当前线程已经拥有了这个对象的锁，只是重新进入，则进入monitor的进入数加1； 如果其他线程已经占用了monitor，则获取monitor的所有权失败，该线程加入EntryList进入阻塞状态等待，直到monitor的Owner为0，再重新尝试获取monitor的所有权； ​ 执行monitorexit指令的线程必须是对象锁所对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者，锁就被释放了。其他在这个monitor的EntryList中阻塞的线程可以尝试去获取这个 monitor 的所有权。 ​ monitorexit指令出现了两次，第1次为同步正常退出释放锁，第2次为发生异步退出释放锁，也就是说获得锁的线程可以通过正常控制路径退出，或者在同步代码块中抛出异常来释放锁。 同步方法 ​ 当Synchronize同步一个方法（既可以是普通方法，也可以是静态方法）时，通过反编译查看，被Synchronized修饰过的方法，在编译后这里面并没monitorenter和monitorexit，相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符，如下图所示： ​ 这其实是一种隐式的方式，JVM就是根据 “ACC_SYNCHRONIZED” 标示符来实现方法的同步的。 ​ “ACC_SYNCHRONIZED”标志用来区分一个方法是否是同步方法。当方法调用时，调用指令将会检查方法的ACC_SYNCHRONIZED是否被设置，如果被设置，当前线程将会获取monitor并设置Owner，设置成功后才执行方法体，最后不管方法是否正常完成都会释放Owner。在方法执行期间，其他任何线程都无法成为同一个monitor对象的Owner。 ​ 这种同步方式与同步代码块的方式本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。","categories":[{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"}],"tags":[{"name":"Synchronized","slug":"Synchronized","permalink":"http://cloud-tour.github.io/tags/Synchronized/"}]},{"title":"Kafka基础","slug":"kafka","date":"2023-03-11T11:18:45.210Z","updated":"2023-04-06T09:14:19.224Z","comments":true,"path":"2023/03/11/kafka/","link":"","permalink":"http://cloud-tour.github.io/2023/03/11/kafka/","excerpt":"","text":"1、介绍Kafka 简介 Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等。 作用 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输 同时支持离线数据处理和实时数据处理 应用场景 异步处理 可以将一些比较耗时的操作放在其他系统中，通过消息队列将需要进行处理的消息进行存储，其他系统可以消费消息队列中的数据 比较常见的：发送短信验证码、发送邮件 系统解耦 原先一个微服务是通过接口（HTTP）调用另一个微服务，这时候耦合很严重，只要接口发生变化就会导致系统不可用 使用消息队列可以将系统进行解耦合，现在第一个微服务可以将消息放入到消息队列中，另一个微服务可以从消息队列中把消息取出来进行处理。进行系统解耦 流量削峰 因为消息队列是低延迟、高可靠、高吞吐的，可以应对大量并发 日志处理 可以使用消息队列作为临时存储，或者一种通信管道 消息队列的两种模型 生产者、消费者模型 生产者负责将消息生产到MQ中 消费者负责从MQ中获取消息 生产者和消费者是解耦的，可能是生产者一个程序、消费者是另外一个程序 消息队列的模式 点对点：一个消费者消费一个消息。当一个消费者消费了队列中的某条数据之后，该条数据则从消息队列中删除。该模式即使有多个消费者同时消费数据，也能保证数据处理的顺序。生产者发送一条消息到queue，只有一个消费者能收到。 发布订阅：多个消费者可以消费一个消息。与点对点消息系统不同的是，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除。在发布-订阅消息系统中，消息的生产者称为发布者，消费者称为订阅者。发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。 2、Kafka的重要组件 broker：kafka集群中包含一个或者多个服务实例（节点），这种服务实例被称为broker（一个broker就是一个节点/一个服务器） Kafka服务器进程，生产者、消费者都要连接broker。 一个集群由多个broker组成，功能实现Kafka集群的负载均衡、容错。 topic：每条发布到kafka集群的消息都属于某个类别，这个类别就叫做topic。 一个Kafka集群中，可以包含多个topic。一个topic可以包含多个分区 是一个逻辑结构，生产、消费消息都需要指定topic partition：partition(分区)是一个物理上的概念，每个topic包含一个或者多个partition 一个topic中的消息可以分布在topic中的不同partition中 offset：偏移量。相对消费者、partition来说，可以通过offset来拉取数据 消息在日志中的位置，可以理解是消息在 partition 上的偏移量，也是代表该消息的唯一序号。 同时也是主从之间的需要同步的信息 segment：一个partition当中存在多个segment文件段，每个segment分为两部分，.log文件和 .index 文件，其中 .index 文件是索引文件，主要用于快速查询， .log 文件当中数据的偏移量位置 replica： partition replicas（分区副本），实现Kafkaf集群的容错，实现partition的容错。一个topic至少应该包含大于1个的副本 producer：消息的生产者，负责发布消息到 kafka 的 broker 中 consumer：消息的消费者，向 kafka 的 broker 中读取消息的客户端 consumer group：消费者组，每一个 consumer 属于一个特定的 consumer group（可以为每个consumer指定 groupName） 一个消费者组中可以包含多个消费者，共同来消费topic中的数据 一个topic中如果只有一个分区，那么这个分区只能被某个组中的一个消费者消费 有多少个分区，那么就可以被同一个组内的多少个消费者消费 .log：存放数据文件 .index：存放.log文件的索引数据 涵盖关系图： 3、Kafka消息幂等性解决 消息幂等问题 拿http举例来说，一次或多次请求，得到地响应是一致的（网络超时等问题除外），换句话说，就是执行多次操作与执行一次操作的影响是一样的。 Kafka生产者生产消息到partition，如果直接发送消息，kafka会将消息保存到分区中，但Kafka会返回一个ack给生产者，表示当前操作是否成功，是否已经保存了这条消息。如果ack响应的过程失败了，此时生产者会重试，继续发送没有发送成功的消息，Kafka又会保存一条一模一样的消息 解决： 当Kafka的生产者生产消息时，会增加一个pid（生产者的唯一编号）和sequence number（针对消息的一个递增序列） PID：每个Producer在初始化时，都会分配一个唯一的PID，这个PID对用户来说，是透明的。 Sequence Number：针对每个生产者（对应PID）发送到指定主题分区的消息都对应一个从0开始递增的Sequence Number。 发送消息，会连着pid和sequence number一块发送 kafka接收到消息，会将消息和pid、sequence number一并保存下来 如果ack响应失败，生产者重试，再次发送消息时，Kafka会根据pid、sequence number是否需要再保存一条消息 判断条件：生产者发送过来的sequence number 是否小于等于 partition中消息对应的sequence 4、消费组Consumer Group Rebalance机制 再均衡：在某些情况下，消费者组中的消费者消费的分区会产生变化，会导致消费者分配不均匀（例如：有两个消费者消费3个，因为某个partition崩溃了，还有一个消费者当前没有分区要削峰），Kafka Consumer Group就会启用rebalance机制，重新平衡这个Consumer Group内的消费者消费的分区分配。 触发时机 消费者数量发生变化 某个消费者crash 新增消费者 topic的数量发生变化 某个topic被删除 partition的数量发生变化 删除partition 新增partition 不良影响 发生rebalance，group中的所有的consumer将不再工作，共同来参与再均衡，直到每个消费者都已经被成功分配所需要消费的分区为止（rebalance结束） 5、Kafka分区策略 生产者的分区写入策略 轮询（按照消息尽量保证每个分区的负载）策略，消息会均匀地分布到每个partition 写入消息的时候，key为null的时候，默认使用的是轮询策略 随机策略（不使用） 按key写入策略，key.hash() % 分区的数量(有可能会出现数据倾斜) 自定义分区策略（类似于MapReduce指定分区） 乱序问题 在Kafka中生产者是有写入策略，如果topic有多个分区，就会将数据分散在不同的partition中存储 当partition数量大于1的时候，数据（消息）会打散分布在不同的partition中 如果只有一个分区，消息是有序的 消费者的分区分配策略 分区分配策略：保障每个消费者尽量能够均衡地消费分区的数据，不能出现某个消费者消费分区的数量特别多，某个消费者消费的分区特别少 Range分配策略（范围分配策略）：Kafka默认的分配策略 n：分区的数量 / 消费者数量 m：分区的数量 % 消费者数量 前m个消费者消费n+1个分区 剩余的消费者消费n个分区 RoundRobin分配策略（轮询分配策略） 消费者挨个分配消费的分区 Striky粘性分配策略 在没有发生rebalance跟轮询分配策略是一致的 发生了rebalance，轮询分配策略，重新走一遍轮询分配的过程。而粘性会保证跟上一次的尽量一致，只是将新的需要分配的分区，均匀的分配到现有可用的消费者中即可 减少上下文的切换 6、副本的ACK策略 producer是不断地往Kafka中写入数据，写入数据会有一个返回结果，表示是否写入成功。这里对应有一个ACKs的配置。 acks = 0：生产者只管写入，不管是否写入成功，可能会数据丢失。性能是最好的 acks = 1：生产者会等到leader分区写入成功后，返回成功，接着发送下一条 acks = -1/all：确保消息写入到leader分区、还确保消息写入到对应副本都成功后，接着发送下一条，性能是最差的 根据业务情况来选择ack机制，是要求性能最高，一部分数据丢失影响不大，可以选择0/1。如果要求数据一定不能丢失，就得配置为-1/all。 分区中是有leader和follower的概念，为了确保消费者消费的数据是一致的，只能从分区leader去读写消息，follower做的事情就是同步数据，Backup。 7、leader和follower 在Kafka中，每个topic都可以配置多个分区以及多个副本。每个分区都有一个leader以及0个或者多个follower，在创建topic时，Kafka会将每个分区的leader均匀地分配在每个broker上。我们正常使用kafka是感觉不到leader、follower的存在的。但其实，所有的读写操作都是由leader处理，而所有的follower都复制leader的日志数据文件，如果leader出现故障时，follower就会被选举为leader。 Kafka中的leader和follower是相对于分区有意义，不是相对broker Kafka在创建topic的时候，会尽量分配分区的leader在不同的broker中，其实就是负载均衡 leader职责：读写数据 follower职责：同步数据、参与选举（leader crash之后，会选举一个follower重新成为分区的leader） 注意和ZooKeeper区分 ZK的leader负责读、写，follower可以读取 Kafka的leader负责读写、follower不能读写数据（确保每个消费者消费的数据是一致的），Kafka一个topic有多个分区leader，一样可以实现数据操作的负载均衡 AR\\ISR\\OSR AR：（Assigned Replicas——已分配的副本）表示一个topic下的所有副本 ISR：（In-Sync Replicas——在同步中的副本）所有与leader副本保持一定程度同步的副本（包括 leader 副本在内）组成 OSR：（Out of Sync Replicas——不再同步的副本）由于follower副本同步滞后过多的副本（不包括 leader 副本）组成 AR = ISR + OSR 正常情况下，所有的follower副本都应该与leader副本保持同步，即AR = ISR，OSR集合为空。 leader选举 Controller：controller是kafka集群的老大，前面leader和follower是针对partition，而controller是针对broker的 Controller是高可用的，是用过ZK来进行选举，一旦某个broker崩溃，其他的broker会重新注册为Controller Kafka启动时，会在所有的broker中选择一个controller 创建topic、或者添加分区、修改副本数量之类的管理任务都是由controller完成的 Kafka分区leader的选举，也是由controller决定的 Leader：是针对partition的一个角色 Leader是通过ISR来进行快速选举 Controller选举Leader 所有Partition的leader选举都由controller决定 controller会将leader的改变直接通过RPC的方式通知需为此作出响应的Broker controller读取到当前分区的ISR，只要有一个Replica还幸存，就选择其中一个作为leader；否则，则任意选这个一个Replica作为leader 如果该partition的所有Replica都已经宕机，则新的leader为-1 为什么不能通过ZK的方式来选举partition的leader？ Kafka集群如果业务很多的情况下，会有很多的partition 假设某个broker宕机，就会出现很多的partiton都需要重新选举leader 如果使用zookeeper选举leader，会给zookeeper带来巨大的压力。所以，kafka中leader的选举不能使用ZK来实现 leader负载均衡 leader的负载均衡 如果某个broker crash之后，就可能会导致partition的leader分布不均匀，就是一个broker上存在一个topic下不同partition的leader Kafka中引入了一个叫做「preferred-replica」的概念，意思就是：优先的Replica 在ISR列表中，第一个replica就是preferred-replica 第一个分区存放的broker，肯定就是preferred-replica 通过以下指令，可以将leader分配到优先的leader对应的broker，确保leader是均匀分配的 1bin/kafka-leader-election.sh --bootstrap-server node1.itcast.cn:9092 --topic test --partition=2 --election-type preferred kafka读写流程 写流程 通过ZooKeeper找partition对应的leader，leader是负责写的 producer开始写入数据 broker进程上的leader将消息写入到本地log中 follower从leader上拉取消息，写入到本地log，并向leader发送ACK leader接收到所有的ISR中的Replica的ACK后，并向生产者返回ACK 读流程 通过ZooKeeper找partition对应的leader，leader是负责读的 通过ZooKeeper找到消费者对应的offset 然后开始从offset往后顺序拉取数据 提交offset（自动提交——每隔多少秒提交一次offset、手动提交——放入到事务中提交） 物理存储 Kafka的数据组织结构 topic partition segment .log数据文件 .index（稀疏索引） .timeindex（根据时间做的索引） 每个日志文件的文件名为起始偏移量，因为每个分区的起始偏移量是0，所以，分区的日志文件都以0000000000000000000.log开始 默认的每个日志文件最大为「log.segment.bytes =102410241024」1G 为了简化根据offset查找消息，Kafka日志文件名设计为开始的偏移量 深入了解读数据的流程 消费者的offset是一个针对partition全局offset 可以根据这个offset找到segment段 接着需要将全局的offset转换成segment的局部offset 根据局部的offset，就可以从（.index稀疏索引）找到对应的数据位置 开始顺序读取 8、Kafka的数据不丢失性 broker消息不丢失：因为有副本relicas的存在，会不断地从leader中同步副本，所以，一个broker crash，不会导致数据丢失，除非是只有一个副本。 生产者消息不丢失: 生产者连接leader写入数据时，可以通过ACK机制来确保数据已经成功写入。ACK机制有三个可选配置 配置ACK响应要求为 -1 时 —— 表示所有的节点都收到数据(leader和follower都接收到数据） 配置ACK响应要求为 1 时 —— 表示leader收到数据 配置ACK影响要求为 0 时 —— 生产者只负责发送数据，不关心数据是否丢失（这种情况可能会产生数据丢失，但性能是最好的） 注意：如果broker端一直不返回ack状态，producer永远不知道是否成功；producer可以设置一个超时时间10s，超过时间认为失败。 生产者可以采用同步和异步两种方式发送数据 同步方式 发送一批数据给kafka后，等待kafka返回结果： 生产者等待10s，如果broker没有给出ack响应，就认为失败 生产者重试3次，如果还没有响应，就报错 异步方式 发送一批数据给kafka，只是提供一个回调函数： 先将数据保存在生产者端的buffer中。buffer大小是2万条 满足数据阈值或者数量阈值其中的一个条件就可以发送数据 发送一批数据的大小是500条 如果broker迟迟不给ack，而buﬀer又满了，开发者可以设置是否直接清空buﬀer中的数据 消费者消费不丢失： 在消费者消费数据的时候，只要每个消费者记录好oﬀset值即可，就能保证数据不丢失。 At-least once：一种数据可能会重复消费 Exactly-Once：仅被一次消费 9、Kafka的数据清理和配额限速 数据清理 Log Deletion（日志删除）：如果消息达到一定的条件（时间、日志大小、offset大小），Kafka就会自动将日志设置为待删除（segment端的后缀名会以 .delete结尾），日志管理程序会定期清理这些日志 默认是7天过期 Log Compaction（日志合并） 如果在一些key-value数据中，一个key可以对应多个不同版本的value 经过日志合并，就会只保留最新的一个版本 配额限速 可以限制Producer、Consumer的速率 防止Kafka的速度过快，占用整个服务器（broker）的所有IO资源 10、Kafka性能好的原因 顺序写磁盘 操作系统每次从磁盘读写数据的时候，需要先寻址，也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写，如果是机械硬盘，寻址就需要较长的时间。 kafka的设计中，数据其实是存储在磁盘上面，一般来说，会把数据存储在内存上面性能才会好。但是kafka用的是顺序写，追加数据是追加到末尾，磁盘顺序写的性能极高，在磁盘个数一定，转数达到一定的情况下，基本和内存速度一致。随机写的话是在文件的某个位置修改数据，性能会较低。 Page Cache Kafka 在 OS 系统方面使用了 Page Cache 而不是我们平常所用的 Buffer。Page Cache 其实不陌生，也不是什么新鲜事物 我们在 linux 上查看内存的时候，经常可以看到 buff/cache，两者都是用来加速 IO 读写用的，而 cache 是作用于读，也就是说，磁盘的内容可以读到 cache 里面这样，应用程序读磁盘就非常快；而 buff 是作用于写，我们开发写磁盘都是，一般如果写入一个 buff 里面再 flush 就非常快。而 kafka 正是把这两者发挥了极致： Kafka 虽然是 scala 写的，但是依旧在 Java 的虚拟机上运行，尽管如此，它尽量避开了 JVM 的限制，它利用了 Page cache 来存储，这样躲开了数据在 JVM 因为 GC 而发生的 STD。另一方面也是 Page Cache 使得它实现了零拷贝，具体下面会讲。 零拷贝 先来看看非零拷贝的情况： 可以看到数据的拷贝从内存拷贝到kafka服务进程那块，又拷贝到socket缓存那块，整个过程耗费的时间比较高，kafka利用了Linux的sendFile技术（NIO），省去了进程切换和一次数据拷贝，让性能变得更好。 传统的一次应用程请求数据的过程 这里大致可以发传统的方式发生了 4 次拷贝，2 次 DMA 和 2 次 CPU，而 CPU 发生了 4 次的切换。（DMA 简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情） 零拷贝的方式 通过优化我们可以发现，CPU 只发生了 2 次的上下文切换和 3 次数据拷贝。（linux 系统提供了系统事故调用函数“ sendfile()”，这样系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态） 分区分段 我们上面也介绍过了，kafka 采取了分区的模式，而每一个分区又对应到一个物理分段，而查找的时候可以根据二分查找快速定位。这样不仅提供了数据读的查询效率，也提供了并行操作的方式。 数据压缩 Kafka 对数据提供了：Gzip 和 Snappy 压缩协议等压缩协议，对消息结构体进行了压缩，一方面减少了带宽，也减少了数据传输的消耗。 11、日志如何分段存储 Kafka规定了一个分区内的.log文件最大为1G，做这个限制目的是为了方便把.log加载到内存去操作 123456789101100000000000000000000.index00000000000000000000.log00000000000000000000.timeindex00000000000005367851.index00000000000005367851.log00000000000005367851.timeindex00000000000009936472.index00000000000009936472.log00000000000009936472.timeindex 这个9936472之类的数字，就是代表了这个日志段文件里包含的起始offset，也就说明这个分区里至少都写入了接近1000万条数据了。Kafka broker有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是1GB，一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log rolling，正在被写入的那个日志段文件，叫做active log segment。如果大家有看前面的两篇有关于HDFS的文章时，就会发现NameNode的edits log也会做出限制，所以这些框架都是会考虑到这些问题。 12、Kafka如何网络设计？ kafka的网络设计和Kafka的调优有关，这也是为什么它能支持高并发的原因： 首先客户端发送请求全部会先发送给一个Acceptor，broker里面会存在3个线程（默认是3个），这3个线程都是叫做processor，Acceptor不会对客户端的请求做任何的处理，直接封装成一个个socketChannel发送给这些processor形成一个队列，发送的方式是轮询，就是先给第一个processor发送，然后再给第二个，第三个，然后又回到第一个。消费者线程去消费这些socketChannel时，会获取一个个request请求，这些request请求中就会伴随着数据。 线程池里面默认有8个线程，这些线程是用来处理request的，解析请求，如果request是写请求，就写到磁盘里。读的话返回结果。 processor会从response中读取响应数据，然后再返回给客户端。这就是Kafka的网络三层架构。 所以如果我们需要对kafka进行增强调优，增加processor并增加线程池里面的处理线程，就可以达到效果。request和response那一块部分其实就是起到了一个缓存的效果，是考虑到processor们生成请求太快，线程数不够不能及时处理的问题。所以这就是一个加强版的reactor网络线程模型。","categories":[{"name":"kafka","slug":"kafka","permalink":"http://cloud-tour.github.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://cloud-tour.github.io/tags/kafka/"}]},{"title":"debian系统下安装nginx","slug":"debian系统下安装nginx","date":"2022-10-08T04:14:18.807Z","updated":"2022-10-08T04:29:18.082Z","comments":true,"path":"2022/10/08/debian系统下安装nginx/","link":"","permalink":"http://cloud-tour.github.io/2022/10/08/debian%E7%B3%BB%E7%BB%9F%E4%B8%8B%E5%AE%89%E8%A3%85nginx/","excerpt":"","text":"​ 博主在工作学习时，经常性使用到nginx，但是某些时候有一些指令总是忘记，去网上收缩有甚是繁琐，因此用本篇博客记录安装的指令，与最后各种文件存放的位置 debian下安装nginx 在安装nginx之前，需要先安装一些插件，使得后面nginx能够正常运行 gcc 1apt install -y build-essential 正则库 1apt install -y libpcre3 libpcre3-dev zlib库 1apt install -y zlib1g-dev OpenSSL库 1apt install -y openssl libssl-dev 下载nginx源码 1234567891011# 下载源码wget http://nginx.org/download/nginx-1.20.2.tar.gz# 解压源码tar -xf nginx-1.20.2.tar.gz# 进入源代码内cd nginx-1.20.2 配置 1234567891011121314151617181920212223242526272829303132333435363738./configure \\--prefix=/usr/local/nginx \\--user=www \\--group=www \\--sbin-path=/usr/local/nginx/sbin/nginx \\--conf-path=/usr/local/nginx/nginx.conf \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--pid-path=/var/run/nginx.pid \\--lock-path=/var/run/nginx.lock \\--http-client-body-temp-path=/var/cache/nginx/client_temp \\--http-proxy-temp-path=/var/cache/nginx/proxy_temp \\--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\--http-scgi-temp-path=/var/cache/nginx/scgi_temp \\--with-file-aio \\--with-threads \\--with-http_addition_module \\--with-http_auth_request_module \\--with-http_dav_module \\--with-http_flv_module \\--with-http_gunzip_module \\--with-http_gzip_static_module \\--with-http_mp4_module \\--with-http_random_index_module \\--with-http_realip_module \\--with-http_secure_link_module \\--with-http_slice_module \\--with-http_ssl_module \\--with-http_stub_status_module \\--with-http_sub_module \\--with-http_v2_module \\--with-mail \\--with-mail_ssl_module \\--with-stream \\--with-stream_realip_module \\--with-stream_ssl_module \\--with-stream_ssl_preread_module 其中： --prefix：Nginx主要安装路径，后续Nginx子目录依照这个变量展开 --user：设置Nginx进程启动时，所属的用户 --group：设置Nginx进程启动时，所属的用户组 编译 1make 安装 1make install 创建systemctl守护，管理Nginx： 1vim /usr/lib/systemd/system/nginx.service 12345678910111213[Unit]Description=nginxAfter=network.target[Service]Type=forkingExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s quitPrivateTmp=true [Install]WantedBy=multi-user.target 启动各服务 123456789systemctl daemon-reload-------------------systemctl start nginx-------------------#观察nginx启动状态systemctl status nginx.service-------------------#查看80线程状态lsof -i:80 nginx命令 如果你是按我的方法编译，那么，需要注意。 /usr/local/nginx：为Nginx编译安装的地址。 /usr/local/nginx/conf/nginx.conf：Nginx默认配置文件。 同时，我们使用systemctl对Nginx进行管理： systemctl start nginx：启动Nginx服务。 systemctl reload nginx：Nginx配置重载。 systemctl stop nginx：停止Nginx服务。 本片文章参考https://www.php.cn/nginx/488924.html","categories":[{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"nginx","slug":"nginx","permalink":"http://cloud-tour.github.io/tags/nginx/"}]},{"title":"debian系统配置java11环境","slug":"debian系统配置java11环境","date":"2022-10-08T03:31:36.963Z","updated":"2022-10-08T03:47:19.584Z","comments":true,"path":"2022/10/08/debian系统配置java11环境/","link":"","permalink":"http://cloud-tour.github.io/2022/10/08/debian%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AEjava11%E7%8E%AF%E5%A2%83/","excerpt":"","text":"​ 博主最近在工作中使用到debian系统，在初始系统中要进行一些配置，使后续的程序能正常运行，因此用该篇文章记录一些配置的步骤。 博主用的debian系统为11.2版本 下载jdk11 分别输入下列两条指令 123apt search openjdk------------------------------sudo apt install default-jdk 输入查看java版本 1java -version 出现下列信息即为安装成功 其他操作 ​ 其实在上述操作后应该就可以正常运行java程序了，但是为了以防万一，再贴出其他操作 debian的系统环境变量 debian系统的环境变量位置位于/etc/profile 入若需要进行配置环境变量，直接vim即可 配置方式： ​ 配置环境变量时，需要先在windows中下载jdk11的安装包，然后传到debian的/etc/java中，再解压。具体信息步骤博主就不在这贴出了。自行百度，很简单的。","categories":[{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"}],"tags":[{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"java11","slug":"java11","permalink":"http://cloud-tour.github.io/tags/java11/"}]},{"title":"proteus8.9与keil4的简单使用","slug":"proteus8.9与keil4的简单使用","date":"2022-10-07T13:45:21.243Z","updated":"2022-10-07T14:28:39.430Z","comments":true,"path":"2022/10/07/proteus8.9与keil4的简单使用/","link":"","permalink":"http://cloud-tour.github.io/2022/10/07/proteus8.9%E4%B8%8Ekeil4%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","excerpt":"","text":"[toc] 最近博主在学51单片机，因此接触到proteus和keil，本篇文章简单介绍一下这两款软件的使用以及如何结合起来，并用这两款软件简单操作一个51单片机实现一个LED灯的闪烁操作。 keil4 ​ 对于keil4，简单来说就是用来写代码的，将代码编译后生成**.hex**文件，将此文件烧入单片机中便可驱动单片机实现某些特定的操作。 创建工程 新建项目 new一个project 选择Atmel下的AT89C51（即51单片机） 下面这个是提醒是否使用汇编，直接选择否，因为我们使用的是c语言 新建.c文件 接下来new一个file文件 ctrl+s保存为.c文件 将该c文件假如到project中 配置项目编译时自动生成.hex文件 编写功能代码 编写代码 下面写的代码是控制p2的0口间隔输出高低电平 1234567891011121314151617181920212223#include&quot;reg51.h&quot;//代表p2口的0处sbit LED0=P2^0;//睡眠函数void sleep(unsigned int n)&#123; unsigned int i = 0,j=0; for(i=0;i&lt;n;i++)&#123; for(j=0;j&lt;120;j++); &#125;&#125;void main()&#123; while(1)&#123; //输出低电平 LED0=0; sleep(5); //输出高电平 LED0=1; sleep(5); &#125;&#125; 写完编译 无error即可 观察项目路径，已生成,hex文件 proteus8.9 ​ 对于proteus来说，可简单理解为是一个用来对单片机仿真的软件，可以用.hex文件驱动单片机进行特定的功能并显现出来。 创建工程 new一个新的工程，不用选择什么，一直下一步直至完成 制作仿真图 添加元器件仓库 添加AT89C51 选中双击即可 同理添加RES和LED-BIBY 置放元器件（单击后即可在图中置放元器件）添加一个电源 连线 修改电阻值（电阻的值必须大于250，否则可能出错） 烧入程序 将.hex文件烧入程序中。双击单片机 烧入成功后即可仿真 end ​ 这样就利用proteus和keil完成一个简单的单片机电路，实现对led控制闪烁。","categories":[{"name":"51单片机","slug":"51单片机","permalink":"http://cloud-tour.github.io/categories/51%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"proteus","slug":"proteus","permalink":"http://cloud-tour.github.io/tags/proteus/"},{"name":"keil","slug":"keil","permalink":"http://cloud-tour.github.io/tags/keil/"}]}],"categories":[{"name":"java","slug":"java","permalink":"http://cloud-tour.github.io/categories/java/"},{"name":"jvm","slug":"jvm","permalink":"http://cloud-tour.github.io/categories/jvm/"},{"name":"juc","slug":"juc","permalink":"http://cloud-tour.github.io/categories/juc/"},{"name":"kafka","slug":"kafka","permalink":"http://cloud-tour.github.io/categories/kafka/"},{"name":"linux","slug":"linux","permalink":"http://cloud-tour.github.io/categories/linux/"},{"name":"51单片机","slug":"51单片机","permalink":"http://cloud-tour.github.io/categories/51%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://cloud-tour.github.io/tags/AOP/"},{"name":"文件存储","slug":"文件存储","permalink":"http://cloud-tour.github.io/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"name":"定时器","slug":"定时器","permalink":"http://cloud-tour.github.io/tags/%E5%AE%9A%E6%97%B6%E5%99%A8/"},{"name":"堆抢占","slug":"堆抢占","permalink":"http://cloud-tour.github.io/tags/%E5%A0%86%E6%8A%A2%E5%8D%A0/"},{"name":"跨代引用","slug":"跨代引用","permalink":"http://cloud-tour.github.io/tags/%E8%B7%A8%E4%BB%A3%E5%BC%95%E7%94%A8/"},{"name":"AQS","slug":"AQS","permalink":"http://cloud-tour.github.io/tags/AQS/"},{"name":"ReentrantLock","slug":"ReentrantLock","permalink":"http://cloud-tour.github.io/tags/ReentrantLock/"},{"name":"Lock","slug":"Lock","permalink":"http://cloud-tour.github.io/tags/Lock/"},{"name":"线程池","slug":"线程池","permalink":"http://cloud-tour.github.io/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"name":"Synchronized","slug":"Synchronized","permalink":"http://cloud-tour.github.io/tags/Synchronized/"},{"name":"kafka","slug":"kafka","permalink":"http://cloud-tour.github.io/tags/kafka/"},{"name":"debian","slug":"debian","permalink":"http://cloud-tour.github.io/tags/debian/"},{"name":"nginx","slug":"nginx","permalink":"http://cloud-tour.github.io/tags/nginx/"},{"name":"java11","slug":"java11","permalink":"http://cloud-tour.github.io/tags/java11/"},{"name":"proteus","slug":"proteus","permalink":"http://cloud-tour.github.io/tags/proteus/"},{"name":"keil","slug":"keil","permalink":"http://cloud-tour.github.io/tags/keil/"}]}